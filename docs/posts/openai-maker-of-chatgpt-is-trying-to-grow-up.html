<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>OpenAI, Maker of ChatGPT, Is Trying to Grow Up | Khanh's feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nytimes.com/2024/09/03/technology/openai-chatgpt-revenue.html">Original</a>
    <h1>OpenAI, Maker of ChatGPT, Is Trying to Grow Up</h1>
    
    <div id="readability-page-1" class="page"><div id="site-content"><div><article id="story"><header><p id="article-summary">The maker of ChatGPT is struggling to transform itself into a profit-driven company while satisfying worries about the safety of artificial intelligence.</p><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="imageContainer-children-Image"><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcset="https://static01.nyt.com/images/2024/08/27/multimedia/00new-openai-sam2-cjqv/00new-openai-sam2-cjqv-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcset="https://static01.nyt.com/images/2024/08/27/multimedia/00new-openai-sam2-cjqv/00new-openai-sam2-cjqv-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcset="https://static01.nyt.com/images/2024/08/27/multimedia/00new-openai-sam2-cjqv/00new-openai-sam2-cjqv-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"/><img alt="Sam Altman, in a gray shirt and jeans, waves as he rides a golf cart." src="https://static01.nyt.com/images/2024/08/27/multimedia/00new-openai-sam2-cjqv/00new-openai-sam2-cjqv-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale" srcset="https://static01.nyt.com/images/2024/08/27/multimedia/00new-openai-sam2-cjqv/00new-openai-sam2-cjqv-articleLarge.jpg?quality=75&amp;auto=webp 600w,https://static01.nyt.com/images/2024/08/27/multimedia/00new-openai-sam2-cjqv/00new-openai-sam2-cjqv-jumbo.jpg?quality=75&amp;auto=webp 1024w,https://static01.nyt.com/images/2024/08/27/multimedia/00new-openai-sam2-cjqv/00new-openai-sam2-cjqv-superJumbo.jpg?quality=75&amp;auto=webp 2048w" sizes="((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 80vw, 100vw" decoding="async" width="600" height="426"/></picture></div><figcaption data-testid="photoviewer-children-ImageCaption"><span>Sam Altman, the chief executive of OpenAI, has brought in a collection of seasoned tech executives over the last year.</span><span><span>Credit...</span><span><span aria-hidden="false">Kevork Djansezian/Getty Images</span></span></span></figcaption></figure></div><div><div><p><a href="https://www.nytimes.com/by/cade-metz"><img alt="Cade Metz" title="Cade Metz" src="https://static01.nyt.com/images/2018/11/26/multimedia/author-cade-metz/author-cade-metz-thumbLarge.png"/></a><a href="https://www.nytimes.com/by/mike-isaac"><img alt="Mike Isaac" title="Mike Isaac" src="https://static01.nyt.com/images/2018/02/16/multimedia/author-mike-isaac/author-mike-isaac-thumbLarge-v3.png"/></a></p></div></div><div data-testid="reading-time-module"><p><time datetime="2024-09-03T05:01:00-04:00">Sept. 3, 2024, <span>5:01 a.m. ET</span></time></p></div></header><section name="articleBody"><div data-testid="companionColumn-0"><div><p>OpenAI, the often troubled standard-bearer of the tech industry’s push into artificial intelligence, is making substantial changes to its management team, and even how it is organized, as it courts investments from some of the wealthiest companies in the world.</p><p>Over the past several months, OpenAI, the maker of the online chatbot ChatGPT, has hired a who’s who of tech executives, disinformation experts and A.I. safety researchers. It has also added seven board members — including a four-star Army general who ran the National Security Agency — while revamping efforts to ensure that its A.I. technologies do not cause serious harm.</p><p>OpenAI is also in talks with investors such as Microsoft, Apple, Nvidia and the investment firm Thrive for a deal that would value it <a href="https://www.nytimes.com/2024/08/28/technology/openai-valuation-funding-deal.html" title="">at $100 billion</a>. And the company is considering changes to its corporate structure that would make it easier to attract investors.</p><p>The San Francisco start-up, after years of public conflict between management and some of its top researchers, is trying to look more like a no-nonsense company ready to lead the tech industry’s march into artificial intelligence. OpenAI is also trying to push last year’s <a href="https://www.nytimes.com/2023/11/22/technology/how-sam-altman-returned-openai.html" title="">high-profile fight over the management of Sam Altman</a>, its chief executive, into the background.</p></div></div><div data-testid="GridBlock-2"><div><figcaption><span>From left: Sarah Friar was the chief executive of Nextdoor. Kevin Weil was Facebook’s vice president of product. Ben Nimmo is a top disinformation investigator, while Joaquin Candela was Facebook&#39;s director of engineering for applied machine learning.</span><span><span>Credit...</span><span>Kevin Dietsch/Getty Images, Nur Photo SRL/Alamy, Alexander Coggin for The New York Times, Stephen Lam/Reuters</span></span></figcaption></div></div><div data-testid="companionColumn-1"><div><p>But interviews with more than 20 current and former OpenAI employees and board members show that the transition has been difficult. Early employees continue to leave, even as new workers and new executives pour in. And rapid growth hasn’t resolved a fundamental question of what OpenAI is supposed to be: Is it a cutting-edge A.I. lab created for the benefit of humanity, or an aspiring industry giant dedicated to profits?</p><p>Today, OpenAI has more than 1,700 employees, and 80 percent of them started after the release of ChatGPT in November 2022. Mr. Altman and other leaders have led the recruitment of executive hires, while the new chairman, Bret Taylor, a former Facebook executive, has overseen the expansion of the board.</p><p>“While start-ups must naturally evolve and adapt as their impact grows, we recognize OpenAI is navigating this transformation at an unprecedented pace,” Mr. Taylor said in a statement emailed to The New York Times. “Our board and the dedicated team at OpenAI remain focused on safely building A.I. that can solve hard problems for everyone.”</p><p>A number of the new executives played prominent roles in other tech companies. Sarah Friar, OpenAI’s new chief financial officer, was the chief executive of Nextdoor. Kevin Weil, OpenAI’s new chief product officer, was the senior vice president of product at Twitter. Ben Nimmo led Facebook’s battle against deceptive social media campaigns. Joaquin Candela oversaw Facebook’s efforts to reduce the risks of artificial intelligence. Now, the two men have similar roles at OpenAI.</p></div></div><div data-testid="companionColumn-2"><div><p>OpenAI also told employees on Friday that Chris Lehane, a veteran of the Clinton White House who had a senior role at Airbnb and joined OpenAI this year, would be its head of global policy.</p><p>But of 13 people who helped found OpenAI in late 2015 with a mission to create artificial general intelligence, or A.G.I. — a machine that can do anything the human brain can do — only three remain. One, Greg Brockman, the company’s president, has taken a leave of absence through the end of the year, citing the need for time off after nearly a decade of work.</p><p>“It is pretty common to see these kinds of additions — and also subtractions — but we are under such bright lights,” said Jason Kwon, OpenAI’s chief strategy officer. “Everything becomes magnified.”</p><p>Since its earliest days as a nonprofit research lab, OpenAI has struggled with arguments over its goals. In 2018, Elon Musk, its primary backer, departed after a <a href="https://www.nytimes.com/2024/03/05/technology/openai-elon-musk-tesla.html" title="">dispute with its other founders</a>. In early 2022, a group of key researchers, worried that commercial forces were pushing OpenAI’s technologies into the marketplace before proper guardrails were in place, <a href="https://www.nytimes.com/2023/12/03/technology/ai-openai-musk-page-altman.html" title="">left to form a rival A.I. outfit, Anthropic</a>.</p><p>Driven by similar concerns, OpenAI’s board <a href="https://www.nytimes.com/2023/11/17/technology/openai-sam-altman-ousted.html" title="">suddenly fired Mr. Altman</a> late last year. He was <a href="https://www.nytimes.com/2023/11/22/technology/openai-sam-altman-returns.html" title="">reinstated five days later</a>.</p></div></div><div data-testid="companionColumn-3"><div><p>OpenAI has split from many of the employees who questioned Mr. Altman and from others who were less interested in building a regular tech company than in doing advanced research. Echoing complaints from other employees, one researcher quit over OpenAI’s efforts to claw back OpenAI shares from employees — potentially worth millions of dollars — if they publicly spoke out against it. OpenAI has since reversed the practice.</p><p>OpenAI is driven by two forces that are not always compatible.</p><p>On one hand, the company is driven by money — lots of it. Annual revenues have now topped $2 billion, according to a person familiar with its income. ChatGPT has more than 200 million users each week — twice the number from nine months ago. It is unclear how much the company is spending each year, though one <a href="https://www.theinformation.com/articles/why-openai-could-lose-5-billion-this-year" title="" rel="noopener noreferrer" target="_blank">estimate</a> puts the figure at $7 billion. Microsoft, which is already OpenAI’s largest investor, earmarked $13 billion toward the A.I. company.</p><p>But OpenAI is considering making big changes to its structure as it looks for more investments. Right now, the board of the original OpenAI — formed as a nonprofit — controls the organization, without official input from investors. As part of its new funding discussions, OpenAI is considering changes that would make its structure more appealing to investors, according to three people familiar with the negotiations. But it has not yet settled on a new structure.</p><p>OpenAI is also driven by technologies that worry many A.I. researchers, including some OpenAI employees. They argue that these technologies could help <a href="https://www.nytimes.com/2023/05/01/technology/ai-problems-danger-chatgpt.html" title="">spread disinformation, drive cyberattacks or even destroy humanity</a>. That tension led to a blowup in November, when four board members, including the chief scientist and co-founder Ilya Sutskever, removed Mr. Altman.</p><p>After Mr. Altman <a href="https://www.nytimes.com/2024/03/08/technology/sam-altman-to-return-to-openais-board-of-directors.html" title="">reasserted his control</a>, a cloud hung over the company. Dr. Sutskever had not returned to work.</p></div></div><div data-testid="companionColumn-4"><p>(The Times <a href="https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html" title="">sued</a> OpenAI and Microsoft in December for copyright infringement of news content related to A.I. systems.)</p></div><div data-testid="ImageBlock-10"><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><div data-testid="lazy-image"></div></div><figcaption data-testid="photoviewer-children-caption"><span>Ilya Sutskever left OpenAI in May and started his own A.I. company.</span><span><span>Credit...</span><span><span aria-hidden="false">Jim Wilson/The New York Times</span></span></span></figcaption></figure></div></div><div data-testid="companionColumn-5"><div><p>With another researcher, Jan Leike, Dr. Sutskever had built OpenAI’s “Superalignment” team, which explored ways of ensuring that its future technologies would not do harm.</p><p>In May, Dr. Sutskever <a href="https://www.nytimes.com/2024/05/14/technology/ilya-sutskever-leaving-openai.html" title="">left OpenAI</a> and <a href="https://www.nytimes.com/2024/06/19/technology/ilya-sutskever-openai-safe-superintelligence.html" title="">started his own A.I. company.</a> Within minutes, Dr. Leike also left, joining Anthropic. “Safety culture and processes have taken a back seat to shiny products,” he <a href="https://x.com/janleike/status/1791498174659715494" title="" rel="noopener noreferrer" target="_blank">said</a>. Dr. Sutskever and Dr. Leike did not respond to requests for comment.</p><p>Others have followed them out the door.</p><p>“I’m still afraid that OpenAI and other A.I. companies don’t have an adequate plan to manage the risks of the human-level and beyond-human-level A.I. systems they are raising billions of dollars to build,” said William Saunders, a researcher who recently left the company.</p></div></div><div data-testid="companionColumn-6"><div><p>As Dr. Sutskever and Dr. Leike departed, OpenAI moved their work under another co-founder, John Schulman. While the Superalignment team had focused on harms that might happen years in the future, the new team explored both near- and long-term risks.</p><p>At the same time, OpenAI hired Ms. Friar as its chief financial officer (she previously held the same role at Square) and Mr. Weil as its chief product officer. Ms. Friar and Mr. Weil did not respond to requests for comment.</p></div></div><div data-testid="ImageBlock-14"><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><div data-testid="lazy-image"></div></div><figcaption data-testid="photoviewer-children-caption"><span>OpenAI rolled out a new feature for ChatGPT, its online, A.I.-powered chatbot, called code interpreter.</span><span><span>Credit...</span><span><span aria-hidden="false">Jackie Molloy for The New York Times</span></span></span></figcaption></figure></div></div><div data-testid="companionColumn-7"><div><p>Some former executives, who spoke on the condition of anonymity because they had signed nondisclosure agreements, expressed skepticism that OpenAI’s troubled past was behind it. Three of them pointed to Aleksander Madry, who once led OpenAI’s Preparedness team, which explored catastrophic A.I. risks. After a disagreement over how he and his team would fit into the larger organization, Dr. Madry moved to a different research project.</p><p>As some employees departed, they were asked to sign legal papers that said they would lose their OpenAI shares if they spoke out against the company. This incited new concerns among the staff, even after the company revoked the practice.</p></div></div><div data-testid="companionColumn-8"><div><p>In early June, a researcher, Todor Markov, posted a message on the company’s internal messaging system announcing his resignation over the issue, according to a copy of the message viewed by The Times.</p><p>He said OpenAI’s leadership had repeatedly misled employees about the issue. Because of this, he argued, the company’s leadership could not be trusted to build A.G.I. — an echo of what the company’s board had said when it fired Mr. Altman.</p><p>“You often talk about our responsibility to develop A.G.I. safely and to distribute the benefits broadly,” he wrote. “How do you expect to be trusted with that responsibility?”</p></div></div><div data-testid="ImageBlock-18"><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><div data-testid="lazy-image"></div></div><figcaption data-testid="photoviewer-children-caption"><span>Paul M. Nakasone, a retired general and former director of the National Security Agency, is one of several new members of OpenAI’s board.</span><span><span>Credit...</span><span><span aria-hidden="false">Anna Moneymaker for The New York Times</span></span></span></figcaption></figure></div></div><div data-testid="companionColumn-9"><p>Days later, OpenAI announced that Paul M. Nakasone, a retired U.S. Army general, had joined its board. On a recent afternoon, he was asked what he thought of the environment he had stepped into, given that he was new to the A.I. field.</p></div><div data-testid="companionColumn-10"><div><p>“New to A.I.? I am not new to A.I.,” he said in a phone interview. “I ran the N.S.A. I have been dealing with this stuff for years.”</p><p>Last month, Dr. Schulman, the co-founder who helped oversee OpenAI’s new safety efforts, also resigned from the company, <a href="https://x.com/johnschulman2/status/1820610863499509855" title="" rel="noopener noreferrer" target="_blank">saying</a> he wanted to return to “hands-on” technical work. He also joined Anthropic.</p><p>“Scaling a company is really hard. You have to make trade-off decisions all the time. And some people might not like those decisions,” Mr. Kwon said. “Things are just a lot more complicated.”</p></div></div></section><div><div><div><p>Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and other emerging areas of technology.<span> <a href="https://www.nytimes.com/by/cade-metz">More about Cade Metz</a></span></p></div><div><p>Mike Isaac is a technology correspondent for The Times based in San Francisco. He regularly covers Facebook and Silicon Valley.<span> <a href="https://www.nytimes.com/by/mike-isaac">More about Mike Isaac</a></span></p></div></div></div></article></div></div></div>
  </body>
</html>
