<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Spain Overhauls Domestic Violence System After Criticism | Khanh's feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nytimes.com/2025/01/17/technology/spain-overhauls-domestic-violence-system-after-criticism.html">Original</a>
    <h1>Spain Overhauls Domestic Violence System After Criticism</h1>
    
    <div id="readability-page-1" class="page"><div id="site-content"><div><div id="in-story-masthead"><div><p><span><a href="https://www.nytimes.com/section/technology">Technology</a></span><span>|</span><span>Spain Overhauls Domestic Violence System After Criticism</span></p><div><p><span>https://www.nytimes.com/2025/01/17/technology/spain-overhauls-domestic-violence-system-after-criticism.html</span></p></div></div></div><article id="story"><header><p id="article-summary">Spain uses an algorithm to score how likely a domestic violence victim is to be abused again. A Times investigation last year identified flaws in the system.</p><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="imageContainer-children-Image"><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcset="https://static01.nyt.com/images/2025/01/17/multimedia/17violence-algorithm-vjhg/17violence-algorithm-vjhg-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcset="https://static01.nyt.com/images/2025/01/17/multimedia/17violence-algorithm-vjhg/17violence-algorithm-vjhg-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcset="https://static01.nyt.com/images/2025/01/17/multimedia/17violence-algorithm-vjhg/17violence-algorithm-vjhg-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"/><img alt="A military police commander sits next to a keyboard and two monitors on an office desk." src="https://static01.nyt.com/images/2025/01/17/multimedia/17violence-algorithm-vjhg/17violence-algorithm-vjhg-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale" srcset="https://static01.nyt.com/images/2025/01/17/multimedia/17violence-algorithm-vjhg/17violence-algorithm-vjhg-articleLarge.jpg?quality=75&amp;auto=webp 600w,https://static01.nyt.com/images/2025/01/17/multimedia/17violence-algorithm-vjhg/17violence-algorithm-vjhg-jumbo.jpg?quality=75&amp;auto=webp 1024w,https://static01.nyt.com/images/2025/01/17/multimedia/17violence-algorithm-vjhg/17violence-algorithm-vjhg-superJumbo.jpg?quality=75&amp;auto=webp 2048w" sizes="((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 60vw, 100vw" decoding="async" width="600" height="600"/></picture></div><figcaption data-testid="photoviewer-children-ImageCaption"><span>Screens showing the VioGén system used by the military police in Seville, Spain. </span><span><span>Credit...</span><span><span aria-hidden="false">Ana Maria Arevalo Gosen for The New York Times</span></span></span></figcaption></figure></div><div><div><div><p><a href="https://www.nytimes.com/by/adam-satariano" itemprop="name">Adam Satariano</a> and <span itemprop="name">Roser Toll Pifarré</span></p><div><p>Adam Satariano reported from London, and Roser Toll Pifarré from Barcelona, Spain.</p></div></div></div></div><p><time datetime="2025-01-17T00:00:21-05:00">Jan. 17, 2025, <span>12:00 a.m. ET</span></time></p></header><section name="articleBody"><div data-testid="companionColumn-0"><div><p>The Spanish government this week announced a major overhaul to a program in which police rely on an algorithm to identify potential repeat victims of domestic violence, after officials faced questions about the system’s effectiveness.</p><p>The program, VioGén, requires police officers to ask a victim a series of questions. Answers are entered into a software program that produces a score — from no risk to extreme risk — intended to flag the women who are most vulnerable to repeat abuse. The score helps determine what police protection and other services a woman can receive.</p><p><a href="https://www.nytimes.com/interactive/2024/07/18/technology/spain-domestic-violence-viogen-algorithm.html" title="">A New York Times investigation</a> last year found that the police were highly reliant on the technology, almost always accepting the decisions made by the VioGén software. Some women whom the algorithm labeled at no risk or low risk for more harm later experienced further abuse, including dozens who were murdered, The Times found.</p><p>Spanish officials said the changes announced this week were part of a long-planned update to the system, which was introduced in 2007. They said the software had helped police departments with limited resources protect vulnerable women and reduce the number of repeat attacks.</p></div></div><div data-testid="companionColumn-1"><div><p>In the updated system, VioGén 2, the software will no longer be able to label women as facing no risk. Police must also enter more information about a victim, which officials said would lead to more accurate predictions.</p><p>Other changes are intended to improve collaboration among government agencies involved in cases of violence against women, including making it easier to share information. In some cases, victims will receive personalized protection plans.</p><p>“Machismo is knocking at our doors and doing so with a violence unlike anything we have seen in a long time,” Ana Redondo, the minister of equality, said at a news conference on Wednesday. “It’s not the time to take a step back. It’s time to take a leap forward.”</p><p>Spain’s use of an algorithm to guide the treatment of gender violence is a far-reaching example of how <a href="https://www.nytimes.com/2020/02/06/technology/predictive-algorithms-crime.html" title="">governments are turning to algorithms</a> to make important societal decisions, a trend that is expected to grow with the use of artificial intelligence. The system has been studied as a potential model for governments elsewhere that are trying to combat violence against women.</p><p>VioGén was created with the belief that an algorithm based on a mathematical model can serve as an unbiased tool to help police find and protect women who may otherwise be missed. The yes-or-no questions include: Was a weapon used? Were there economic problems? Has the aggressor shown controlling behaviors?</p></div></div><div data-testid="companionColumn-2"><div><p>Victims classified as higher risk received more protection, including regular patrols by their home, access to a shelter and police monitoring of their abuser’s movements. Those with lower scores got less aid.</p><p>As of November, Spain had more than 100,000 active cases of women who had been evaluated by VioGén, with about 85 percent of the victims classified as facing little risk of being hurt by their abuser again. Police officers in Spain are trained to overrule VioGén’s recommendations if evidence warrants doing so, but The Times found that the risk scores were accepted about 95 percent of the time.</p><p>Victoria Rosell, a judge in Spain and a former government delegate focused on gender violence issues, said a period of “self-criticism” was needed for the government to improve VioGén. She said the system could be more accurate it if pulled information from additional government databases, including health care and education systems.</p><p>Natalia Morlas, president of Somos Más, a victims’ rights group, said she welcomed the changes, which she hoped would lead to better risk assessments by the police.</p><p>“Calibrating the victim’s risk well is so important that it can save lives,” Ms. Morlas said. She added that it was critical to maintain close human oversight of the system because a victim “has to be treated by people, not by machines.”</p></div></div></section></article></div></div></div>
  </body>
</html>
