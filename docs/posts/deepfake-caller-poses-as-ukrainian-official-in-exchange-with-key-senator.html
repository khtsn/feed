<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>‘Deepfake’ Caller Poses as Ukrainian Official in Exchange With Key Senator | Khanh's feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nytimes.com/2024/09/26/us/senator-cardin-deepfake.html">Original</a>
    <h1>‘Deepfake’ Caller Poses as Ukrainian Official in Exchange With Key Senator</h1>
    
    <div id="readability-page-1" class="page"><div><p>Mr. Cardin, a Maryland Democrat, also partially confirmed the episode in a statement Wednesday night. In it, he acknowledged that “in recent days, a malign actor engaged in a deceptive attempt to have a conversation with me by posing as a known individual.” Mr. Cardin did not say the individual was Mr. Kuleba or make any reference to Ukraine.</p><p>The operation was <a href="https://punchbowl.news/archive/cardin_ukraine_deepfake/" title="" rel="noopener noreferrer" target="_blank">reported earlier by Punchbowl News</a>.</p><p><a href="https://www.nytimes.com/2018/03/04/technology/fake-videos-deepfakes.html" title="">Deepfake video technology uses artificial intelligence</a> to create video of fictitious people who look and sound real. The technology has sometimes been used to impersonate public figures, including a video that circulated on social media in 2022 falsely showing President Volodymyr Zelensky of Ukraine <a href="https://www.nytimes.com/2022/04/05/us/politics/ukraine-russia-hackers.html" title="">announcing a surrender</a> in the war with Russia.</p><p>Mr. Cardin is retiring at the end of the year. But the episode has renewed fears that foreign actors could try to target lawmakers, particularly now in a bid to influence the outcome of the November election.</p><p>It was not immediately clear who had orchestrated the operation that targeted Mr. Cardin. Intelligence officials have warned that foreign actors such as Russia, Iran and China are exploiting artificial intelligence, including deepfakes, to augment their election interference efforts — with Russia generating the most content, the Office of the Director of National Intelligence said this week.</p><p>While it is unclear if Russia was behind the impersonation of Mr. Kuleba, some of the questions asked of Mr. Cardin would be of particular interest to Russia — particularly when, according to the Senate security office’s email, the impersonator asked him: “Do you support long-range missiles into Russian territory? I need to know your answer.”</p></div></div>
  </body>
</html>
