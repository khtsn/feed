<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Former OpenAI Researcher Says Company Broke Copyright Law | Khanh's feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nytimes.com/2024/10/23/technology/openai-copyright-law.html">Original</a>
    <h1>Former OpenAI Researcher Says Company Broke Copyright Law</h1>
    
    <div id="readability-page-1" class="page"><div id="site-content"><div><article id="story"><div><div><div><div><div><nav aria-labelledby="storyline-menu-title" role="navigation"><ul role="menu"><li><span data-testid="menu-link"><a role="menuitem" href="https://www.nytimes.com/2024/10/17/technology/microsoft-openai-partnership-deal.html"><span>Microsoft-OpenAI Partnership Frays</span></a></span></li><li><span data-testid="menu-link"><a role="menuitem" href="https://www.nytimes.com/2024/10/09/technology/personaltech/turn-off-ai-overviews-google-meta.html"><span>Turning Off A.I. Tools</span></a></span></li><li><span data-testid="menu-link"><a role="menuitem" href="https://www.nytimes.com/2024/10/04/technology/meta-instant-ai-video-generator-adds-sounds.html"><span>Meta’s Video Generator</span></a></span></li><li><span data-testid="menu-link"><a role="menuitem" href="https://www.nytimes.com/2024/10/02/technology/personaltech/apple-intelligence-iphone.html"><span>Testing Apple Intelligence</span></a></span></li><li><span data-testid="menu-link"><a role="menuitem" href="https://www.nytimes.com/2024/09/23/technology/ai-chatbots-chatgpt-math.html"><span>Can Math Help Chatbots?</span></a></span></li></ul></nav></div></div></div></div></div><section name="articleBody"><div data-testid="companionColumn-0"><div><p>Suchir Balaji spent nearly four years as an artificial intelligence researcher at OpenAI. Among other projects, he helped gather and organize <a href="https://www.nytimes.com/2024/04/06/technology/tech-giants-harvest-data-artificial-intelligence.html" title="">the enormous amounts of internet data</a> the company used to build its online chatbot, ChatGPT.</p><p>At the time, he did not carefully consider whether the company had a legal right to build its products in this way. He assumed the San Francisco start-up was free to use any internet data, whether it was copyrighted or not.</p><p>But after the <a href="https://www.nytimes.com/2022/12/10/technology/ai-chat-bot-chatgpt.html" title="">release of ChatGPT in late 2022</a>, he thought harder about what the company was doing. He came to the conclusion that OpenAI’s use of copyrighted data violated the law and that technologies like ChatGPT were damaging the internet.</p><p>In August, he left OpenAI because he no longer wanted to contribute to technologies that he believed would bring society more harm than benefit.</p></div></div><div data-testid="companionColumn-1"><div><p>“If you believe what I believe, you have to just leave the company,” he said during a recent series of interviews with The New York Times.</p><p>Mr. Balaji, 25, who has not taken a new job and is working on what he calls “personal projects,” is among the first employees to leave a major A.I. company and speak out publicly against the way these companies have used copyrighted data to create their technologies. A former vice president at the London start-up Stability AI, which specializes in image- and audio-generating technologies, has made <a href="https://www.musicbusinessworldwide.com/why-just-resigned-from-my-job-generative-ai/" title="" rel="noopener noreferrer" target="_blank">similar arguments</a>.</p><p>Over the past two years, a number of individuals and businesses have sued various A.I. companies, including OpenAI, arguing that they illegally used copyrighted material to train their technologies. Those who have filed suits include <a href="https://www.nytimes.com/2022/11/23/technology/copilot-microsoft-ai-lawsuit.html" title="">computer programmers</a>, <a href="https://www.theverge.com/2023/1/16/23557098/generative-ai-art-copyright-legal-lawsuit-stable-diffusion-midjourney-deviantart" title="" rel="noopener noreferrer" target="_blank">artists</a>, <a href="https://www.nytimes.com/2024/06/25/arts/music/record-labels-ai-lawsuit-sony-universal-warner.html" title="">record labels</a>, <a href="https://www.nytimes.com/2023/09/20/books/authors-openai-lawsuit-chatgpt-copyright.html" title="">book authors</a> and <a href="https://www.nytimes.com/2024/04/30/business/media/newspapers-sued-microsoft-openai.html" title="">news organizations</a>.</p><p>In December, The New York Times <a href="https://www.nytimes.com/2024/10/09/technology/google-nobel-prize-antitrust.html" title="">sued</a> OpenAI and its primary partner, Microsoft, claiming they used millions of articles published by The Times to build chatbots that now compete with the news outlet as a source of reliable information. Both companies have denied the claims.</p><p>Many researchers who have worked inside OpenAI and other tech companies have <a href="https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html" title="">cautioned that A.I. technologies could cause serious harm</a>. But most of those warnings have been about future risks, like A.I. systems that could one day help create new bioweapons or <a href="https://www.nytimes.com/2023/06/10/technology/ai-humanity.html" title="">even destroy humanity</a>.</p></div></div><div data-testid="companionColumn-2"><div><p>Mr. Balaji believes the threats are more immediate. ChatGPT and other chatbots, he said, are destroying the commercial viability of the individuals, businesses and internet services that created the digital data used to train these A.I. systems.</p><p>“This is not a sustainable model for the internet ecosystem as a whole,” he told The Times.</p><p>OpenAI disagrees with Mr. Balaji, saying in a statement: “We build our A.I. models using publicly available data, in a manner protected by fair use and related principles, and supported by longstanding and widely accepted legal precedents. We view this principle as fair to creators, necessary for innovators, and critical for US competitiveness.”</p></div></div><div data-testid="ImageBlock-5"><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcset="https://static01.nyt.com/images/2024/10/15/multimedia/OPENAI-DATA-OPENAI-zvfg/OPENAI-DATA-OPENAI-zvfg-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcset="https://static01.nyt.com/images/2024/10/15/multimedia/OPENAI-DATA-OPENAI-zvfg/OPENAI-DATA-OPENAI-zvfg-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcset="https://static01.nyt.com/images/2024/10/15/multimedia/OPENAI-DATA-OPENAI-zvfg/OPENAI-DATA-OPENAI-zvfg-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"/><img alt="The OpenAI offices, with two scooters parked in the front and the number 1960 over a black doorway. Lights and plants are visible from large windows." src="https://static01.nyt.com/images/2024/10/15/multimedia/OPENAI-DATA-OPENAI-zvfg/OPENAI-DATA-OPENAI-zvfg-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale" srcset="https://static01.nyt.com/images/2024/10/15/multimedia/OPENAI-DATA-OPENAI-zvfg/OPENAI-DATA-OPENAI-zvfg-articleLarge.jpg?quality=75&amp;auto=webp 600w,https://static01.nyt.com/images/2024/10/15/multimedia/OPENAI-DATA-OPENAI-zvfg/OPENAI-DATA-OPENAI-zvfg-jumbo.jpg?quality=75&amp;auto=webp 1024w,https://static01.nyt.com/images/2024/10/15/multimedia/OPENAI-DATA-OPENAI-zvfg/OPENAI-DATA-OPENAI-zvfg-superJumbo.jpg?quality=75&amp;auto=webp 2048w" sizes="((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 80vw, 100vw" uri="nyt://image/26b1f622-81a1-5e87-876a-aa9295ea5bd7" decoding="async" width="600" height="400"/></picture></div><figcaption data-testid="photoviewer-children-caption"><span>The OpenAI offices in San Francisco. Many researchers who have worked at the company and other leading tech companies have publicly warned that A.I. technologies could cause serious harm.</span><span><span>Credit...</span><span><span aria-hidden="false">Jason Henry for The New York Times</span></span></span></figcaption></figure></div></div><div data-testid="companionColumn-3"><div><p>In 2013, an artificial intelligence start-up in London called DeepMind unveiled A.I. technology that <a href="https://www.youtube.com/watch?v=TmPfTpjtdgg" title="" rel="noopener noreferrer" target="_blank">learned to play classic Atari games on its own</a>, including Space Invaders, Pong and Breakout.</p><p>When Mr. Balaji was a teenager growing up in Cupertino, Calif., he stumbled across a news story about the technology. It captured his imagination, as did a <a href="https://www.wired.com/2016/05/google-alpha-go-ai/" title="" rel="noopener noreferrer" target="_blank">later DeepMind creation that mastered the ancient game of Go</a>.</p></div></div><div data-testid="companionColumn-4"><div><p>“I thought that A.I. was a thing that could be used to solve unsolvable problems, like curing diseases and stopping aging,” he said. “I thought we could invent some kind of scientist that could help solve them.”</p><p>During a gap year after high school and as a computer science student at the University of California, Berkeley, Mr. Balaji began exploring the key idea behind DeepMind’s technologies: <a href="https://www.nytimes.com/2018/03/06/technology/google-artificial-intelligence.html" title="">a mathematical system called a neural network</a> that could learn skills by analyzing digital data.</p><p>In 2020, he joined a stream of Berkeley grads who went to work for OpenAI. In early 2022, Mr. Balaji began gathering digital data for a <a href="https://www.nytimes.com/2023/03/14/technology/openai-gpt4-chatgpt.html" title="">new project called GPT-4</a>. This was a neural network that <a href="https://www.nytimes.com/2024/04/06/technology/tech-giants-harvest-data-artificial-intelligence.html" title="">spent months analyzing practically all the English language text on the internet</a>.</p></div></div><div data-testid="ImageBlock-9"><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><div data-testid="lazy-image"></div></div><figcaption data-testid="photoviewer-children-caption"><span>Suchir Balaji began exploring ideas behind neural networks long before he took a job at OpenAI.</span><span><span>Credit...</span><span><span aria-hidden="false">Ulysses Ortega for The New York Times</span></span></span></figcaption></figure></div></div><div data-testid="companionColumn-5"><p>He and his colleagues, Mr. Balaji said, treated it like a research project. Though OpenAI had recently transformed itself into a profit-making company and had started selling access to <a href="https://www.nytimes.com/2020/11/24/science/artificial-intelligence-ai-gpt3.html" title="">similar technology called GPT-3</a>, they did not think of their work as something that would compete with existing internet services. GPT-3 was not a chatbot. It was a technology that allowed businesses and computer coders to build other software apps.</p></div><div data-testid="companionColumn-6"><div><p>“With a research project, you can, generally speaking, train on any data,” Mr. Balaji said. “That was the mind-set at the time.”</p><p>Then OpenAI released ChatGPT. Initially driven by a precursor to GPT-4 and later by GPT-4 itself, the chatbot grabbed the attention of hundreds of millions of people and quickly became a <a href="https://www.nytimes.com/2024/09/27/technology/openai-chatgpt-investors-funding.html" title="">moneymaker</a>.</p><p>OpenAI, Microsoft and other companies have said that using internet data to train their A.I. systems meets the requirements of the “fair use” doctrine. The doctrine has four factors. The companies argue that those factors — including that they substantially transformed the copyrighted works and were not competing in the same market with a direct substitute for those works — play in their favor.</p><p>Mr. Balaji does not believe these criteria have been met. When a system like GPT-4 learns from data, he said, it makes a complete copy of that data. From there, a company like OpenAI can then teach the system to generate an exact copy of the data. Or it can teach the system to generate text that is in no way a copy. The reality, he said, is that companies teach the systems to do something in between.</p><p>“The outputs aren’t exact copies of the inputs, but they are also not fundamentally novel,” he said. This week, he posted an <a href="http://suchir.net/fair_use.html" title="" rel="noopener noreferrer" target="_blank">essay on his personal website</a> that included what he describes as a mathematical analysis that aims to show that this claim is true.</p></div></div><div data-testid="companionColumn-7"><div><p>Mark Lemley, a Stanford University law professor, argued the opposite. Most of what chatbots put out, he said, is sufficiently different from its training data.</p><p>“There are occasionally circumstances where an output looks like an input,” he said. “A vast majority of things generated by a ChatGPT or an image generation system do not draw heavily from a particular piece of content.”</p></div></div><div data-testid="ImageBlock-15"><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><div data-testid="lazy-image"></div></div><figcaption data-testid="photoviewer-children-caption"><span>ChatGPT-4o on an iPhone.</span><span><span>Credit...</span><span><span aria-hidden="false">Arsenii Vaselenko for The New York Times</span></span></span></figcaption></figure></div></div><div data-testid="companionColumn-8"><div><p>The technology violates the law, Mr. Balaji argued, because in many cases it directly competes with the copyrighted works it learned from. Generative models are designed to imitate online data, he said, so they can substitute for “basically anything” on the internet, from news stories to online forums.</p><p>The larger problem, he said, is that as A.I. technologies replace existing internet services, they are generating false and sometimes completely made-up information — what researchers call “<a href="https://www.nytimes.com/2023/05/01/business/ai-chatbots-hallucination.html" title="">hallucinations</a>.” The internet, he said, is changing for the worse.</p></div></div><div data-testid="companionColumn-9"><div><p>Bradley J. Hulbert, an intellectual property lawyer who specializes in this intellectual property law, said that the intellectual copyright laws now in place were written well before the rise of A.I. and that no court has yet decided whether A.I. technologies like ChatGPT violate the law.</p><p>He also argued that Congress should create a new law that addresses this technology. “Given that A.I. is evolving so quickly,” he said, “it is time for Congress to step in.”</p><p>Mr. Balaji agreed. “The only way out of all this is regulation,” he said.</p></div></div><div data-testid="RelatedLinksBlock-19"></div></section><div><div><div><p>Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and other emerging areas of technology.<span> </span></p></div></div><div><p>See more on: <a href="https://www.nytimes.com/topic/openai">OpenAI</a></p></div><div role="toolbar" data-testid="share-tools" aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count"><div><ul><li><div></div></li><li><div></div></li><li></li></ul></div></div></div><div><div><section id="styln-guide" role="complementary" aria-labelledby="styln-guide-title"><hr/><h2 id="styln-guide-title">Explore Our Coverage of Artificial Intelligence</h2><hr/><p><strong>News</strong><strong> and Analysis</strong></p><ul><li><p>Cerebras, a chip company with bold ambitions to take on Nvidia, <a href="https://www.nytimes.com/2024/09/30/technology/cerebras-ai-chips-ipo.html">filed for an I.P.O.</a>, taking a key step toward being among the first A.I. companies to go public since the release of ChatGPT.</p></li><li><p>Gov. Gavin Newsom <a href="https://www.nytimes.com/2024/09/29/technology/california-ai-bill.html">vetoed a California A.I. safety bill</a>, blocking the most ambitious proposal in the nation aimed at curtailing the growth of the technology.</p></li><li><p>At an event in Silicon Valley, Meta exhibited a range of products, including <a href="https://www.nytimes.com/2024/09/25/technology/meta-products-artificial-intelligence.html">new smart glasses</a>, meant to blend the real world and virtual reality with a healthy dose of A.I.</p></li></ul><hr/><p><strong>The Age of A.I.</strong></p><ul><li><p>Nevada used A.I. to find students in need of help. The new system <a href="https://www.nytimes.com/2024/10/11/us/nevada-ai-at-risk-students.html">cut the number of students deemed “at risk” in the state by 200,000</a>, leading to tough moral and ethical questions over which children deserve extra assistance.</p></li><li><p>A project at Stanford points to the need for institutional innovation, especially in government, to <a href="https://www.nytimes.com/2024/09/24/business/ai-democracy-government.html">increase the odds that A.I. enhances democracy</a>.</p></li><li><p>From hurricanes to wildfires, a new generation of technologies driven by artificial intelligence could <a href="https://www.nytimes.com/2024/09/27/climate/power-outages-utilities-ai.html">help utilities better plan for the risk of extreme weather to their electric grid</a>.</p></li></ul></section></div></div><div id="bottom-sheet-sensor"></div><div><div id="bottom-wrapper"><p>Advertisement</p><p><a href="#after-bottom">SKIP ADVERTISEMENT</a></p></div></div></article></div></div></div>
  </body>
</html>
