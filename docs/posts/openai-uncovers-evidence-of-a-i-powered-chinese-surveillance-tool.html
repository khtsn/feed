<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>OpenAI Uncovers Evidence of A.I.-Powered Chinese Surveillance Tool | Khanh's feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nytimes.com/2025/02/21/technology/openai-chinese-surveillance.html">Original</a>
    <h1>OpenAI Uncovers Evidence of A.I.-Powered Chinese Surveillance Tool</h1>
    
    <div id="readability-page-1" class="page"><div id="site-content"><div><article id="story"><header><p id="article-summary">The company said a Chinese operation had built the tool to identify anti-Chinese posts on social media services in Western countries.</p><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="imageContainer-children-Image"><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcset="https://static01.nyt.com/images/2025/02/21/multimedia/21OPENAI-CHINA-vcpk/21OPENAI-CHINA-vcpk-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcset="https://static01.nyt.com/images/2025/02/21/multimedia/21OPENAI-CHINA-vcpk/21OPENAI-CHINA-vcpk-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcset="https://static01.nyt.com/images/2025/02/21/multimedia/21OPENAI-CHINA-vcpk/21OPENAI-CHINA-vcpk-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"/><img alt="Silhouettes in front of the Chinese national emblem." src="https://static01.nyt.com/images/2025/02/21/multimedia/21OPENAI-CHINA-vcpk/21OPENAI-CHINA-vcpk-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale" srcset="https://static01.nyt.com/images/2025/02/21/multimedia/21OPENAI-CHINA-vcpk/21OPENAI-CHINA-vcpk-articleLarge.jpg?quality=75&amp;auto=webp 600w,https://static01.nyt.com/images/2025/02/21/multimedia/21OPENAI-CHINA-vcpk/21OPENAI-CHINA-vcpk-jumbo.jpg?quality=75&amp;auto=webp 1024w,https://static01.nyt.com/images/2025/02/21/multimedia/21OPENAI-CHINA-vcpk/21OPENAI-CHINA-vcpk-superJumbo.jpg?quality=75&amp;auto=webp 2048w" sizes="((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 80vw, 100vw" decoding="async" width="600" height="394"/></picture></div><figcaption data-testid="photoviewer-children-ImageCaption"><span>Researchers said they had discovered a Chinese surveillance tool when someone working on it used OpenAI technology to debug the computer code.</span><span><span>Credit...</span><span><span aria-hidden="false">Kevin Frayer/Getty Images</span></span></span></figcaption></figure></div><p><time datetime="2025-02-21T09:30:06-05:00">Feb. 21, 2025, <span>9:30 a.m. ET</span></time></p></header><section name="articleBody"><div data-testid="companionColumn-0"><div><p>OpenAI said on Friday that it had uncovered evidence that a Chinese security operation had built an artificial intelligence-powered surveillance tool to gather real-time reports about anti-Chinese posts on social media services in Western countries.</p><p>The company’s researchers said they had identified this new campaign, which they called Peer Review, because someone working on the tool used OpenAI’s technologies to debug some of the computer code that underpins it.</p><p>Ben Nimmo, a principal investigator for OpenAI, said this was the first time the company had uncovered an A.I.-powered surveillance tool of this kind.</p><p>“Threat actors sometimes give us a glimpse of what they are doing in other parts of the internet because of the way they use our A.I. models,” Mr. Nimmo said.</p></div></div><div data-testid="companionColumn-1"><div><p>There have been growing concerns that A.I. can be used for surveillance, computer hacking, disinformation campaigns and other malicious purposes. Though researchers like Mr. Nimmo say the technology can certainly enable these kinds of activities, they add that A.I. can also help identify and stop such behavior.</p><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><div data-testid="lazy-image"></div></div><figcaption data-testid="photoviewer-children-caption"><span>Ben Nimmo, a principal investigator for OpenAI.</span><span><span>Credit...</span><span><span aria-hidden="false">Alexander Coggin For The New York Times</span></span></span></figcaption></figure></div><p>Mr. Nimmo and his team believe the Chinese surveillance tool is based on Llama, an A.I. technology built by Meta, which open sourced its technology, meaning it <a href="https://www.nytimes.com/2023/05/18/technology/ai-meta-open-source.html" title="">shared its work with software developers across the globe</a>.</p><p>In a detailed report on the use of A.I. for malicious and deceptive purposes, OpenAI also said it had uncovered a separate Chinese campaign, called Sponsored Discontent, that used OpenAI’s technologies to generate English-language posts that criticized Chinese dissidents.</p><p>The same group, OpenAI said, has used the company’s technologies to translate articles into Spanish before distributing them in Latin America. The articles criticized U.S. society and politics.</p></div></div><div data-testid="companionColumn-2"><div><p>Separately, OpenAI researchers identified a campaign, believed to be based in Cambodia, that used the company’s technologies to generate and translate social media comments that helped drive a scam known as “<a href="https://www.nytimes.com/2025/02/19/magazine/cryptocurrency-scam-kansas-heartland-bank.html" title="">pig butchering</a>,” the report said. The A.I.-generated comments were used to woo men on the internet and entangle them in an investment scheme.</p><p>(The New York Times has <a href="https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html" title="">sued</a> OpenAI and Microsoft for copyright infringement of news content related to A.I. systems. OpenAI and Microsoft have denied those claims.)</p></div></div></section><div><div><div><p>Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and other emerging areas of technology.<span> <a href="https://www.nytimes.com/by/cade-metz">More about Cade Metz</a></span></p></div></div></div></article></div></div></div>
  </body>
</html>
