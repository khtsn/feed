<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Powerful A.I. Is Coming. We’re Not Ready. | Khanh's feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nytimes.com/2025/03/14/technology/why-im-feeling-the-agi.html">Original</a>
    <h1>Powerful A.I. Is Coming. We’re Not Ready.</h1>
    
    <div id="readability-page-1" class="page"><div id="site-content"><div><article id="story"><div><div><div><div><div><nav aria-labelledby="storyline-menu-title" role="navigation"><ul role="menu"><li><span data-testid="menu-link"><a role="menuitem" href="https://www.nytimes.com/2025/02/27/technology/personaltech/vibecoding-ai-software-programming.html"><span>What is Vibecoding?</span></a></span></li><li><span data-testid="menu-link"><a role="menuitem" href="https://www.nytimes.com/2025/03/05/technology/elon-musk-openai-profit-lawsuit.html"><span>OpenAI and Musk</span></a></span></li><li><span data-testid="menu-link"><a role="menuitem" href="https://www.nytimes.com/2025/02/10/technology/ai-summit-paris-technology.html"><span>Paris A.I. Summit</span></a></span></li><li><span data-testid="menu-link"><a role="menuitem" href="https://www.nytimes.com/2025/02/01/technology/openai-operator-agent.html"><span>A Look at OpenAI’s Operator</span></a></span></li><li><span data-testid="menu-link"><a role="menuitem" href="https://www.nytimes.com/interactive/2024/12/27/technology/artificial-intelligence-generative-fill-photoshop-openai.html"><span>Quiz</span></a></span></li></ul></nav></div></div></div></div></div><section name="articleBody"><div data-testid="companionColumn-0"><div><p>Here are some things I believe about artificial intelligence:</p><p>I believe that over the past several years, A.I. systems have started surpassing humans in a number of domains — <a href="https://www.nytimes.com/2024/07/25/science/ai-math-alphaproof-deepmind.html" title="">math</a>, <a href="https://arxiv.org/html/2502.06807v1" title="" rel="noopener noreferrer" target="_blank">coding</a> and <a href="https://www.nytimes.com/2024/11/17/health/chatgpt-ai-doctors-diagnosis.html" title="">medical diagnosis</a>, just to name a few — and that they’re getting better every day.</p><p>I believe that very soon — probably in 2026 or 2027, but possibly as soon as this year — one or more A.I. companies will claim they’ve created an artificial general intelligence, or A.G.I., which is usually defined as something like “a general-purpose A.I. system that can do almost all cognitive tasks a human can do.”</p><p>I believe that when A.G.I. is announced, there will be debates over definitions and arguments about whether or not it counts as “real” A.G.I., but that these mostly won’t matter, because the broader point — that we are losing our monopoly on human-level intelligence, and transitioning to a world with very powerful A.I. systems in it — will be true.</p><p>I believe that over the next decade, powerful A.I. will generate trillions of dollars in economic value and tilt the balance of political and military power toward the nations that control it — and that most governments and big corporations already view this as obvious, as evidenced by the huge sums of money they’re spending to get there first.</p></div></div><div data-testid="companionColumn-1"><div><p>I believe that most people and institutions are totally unprepared for the A.I. systems that exist today, let alone more powerful ones, and that there is no realistic plan at any level of government to mitigate the risks or capture the benefits of these systems.</p><p>I believe that hardened A.I. skeptics — who insist that the progress is all smoke and mirrors, and who dismiss A.G.I. as a delusional fantasy — not only are wrong on the merits, but are giving people a false sense of security.</p><p>I believe that whether you think A.G.I. will be great or terrible for humanity — and honestly, it may be too early to say — its arrival raises important economic, political and technological questions to which we currently have no answers.</p><p>I believe that the right time to start preparing for A.G.I. is now.</p><p>This may all sound crazy. But I didn’t arrive at these views as a starry-eyed futurist, an investor hyping my A.I. portfolio or a guy who took too many magic mushrooms and watched “Terminator 2.”</p><p>I arrived at them as a journalist who has spent a lot of time talking to the engineers building powerful A.I. systems, the investors funding it and the researchers studying its effects. And I’ve come to believe that what’s happening in A.I. right now is bigger than most people understand.</p></div></div><div data-testid="companionColumn-2"><p>In San Francisco, where I’m based, the idea of A.G.I. isn’t fringe or exotic. People here <a href="https://x.com/polynoamial/status/1899658588626579627" title="" rel="noopener noreferrer" target="_blank">talk about</a> “feeling the A.G.I.,” and building smarter-than-human A.I. systems has become the explicit goal of some of Silicon Valley’s biggest companies. Every week, I meet engineers and entrepreneurs working on A.I. who tell me that change — big change, world-shaking change, the kind of transformation we’ve never seen before — is just around the corner.</p></div><div data-testid="ImageBlock-5"><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcset="https://static01.nyt.com/images/2025/03/12/multimedia/ROOSE-agi-1-01-czwm/ROOSE-agi-1-01-czwm-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcset="https://static01.nyt.com/images/2025/03/12/multimedia/ROOSE-agi-1-01-czwm/ROOSE-agi-1-01-czwm-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcset="https://static01.nyt.com/images/2025/03/12/multimedia/ROOSE-agi-1-01-czwm/ROOSE-agi-1-01-czwm-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"/><img alt="A view of San Francisco, with tall buildings filling out the skyline in the background and shorter, residential buildings in the foreground." src="https://static01.nyt.com/images/2025/03/12/multimedia/ROOSE-agi-1-01-czwm/ROOSE-agi-1-01-czwm-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale" srcset="https://static01.nyt.com/images/2025/03/12/multimedia/ROOSE-agi-1-01-czwm/ROOSE-agi-1-01-czwm-articleLarge.jpg?quality=75&amp;auto=webp 600w,https://static01.nyt.com/images/2025/03/12/multimedia/ROOSE-agi-1-01-czwm/ROOSE-agi-1-01-czwm-jumbo.jpg?quality=75&amp;auto=webp 1024w,https://static01.nyt.com/images/2025/03/12/multimedia/ROOSE-agi-1-01-czwm/ROOSE-agi-1-01-czwm-superJumbo.jpg?quality=75&amp;auto=webp 2048w" sizes="((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 80vw, 100vw" uri="nyt://image/23086e4d-26ee-514e-950c-316e92a14ba8" decoding="async" width="600" height="400"/></picture></div><figcaption data-testid="photoviewer-children-caption"><span>In San Francisco, where prominent A.I. start-ups are based, people talk about “feeling the A.G.I.”</span><span><span>Credit...</span><span><span aria-hidden="false">Mike Kai Chen for The New York Times</span></span></span></figcaption></figure></div></div><div data-testid="companionColumn-3"><div><p>“Over the past year or two, what used to be called ‘short timelines’ (thinking that A.G.I. would probably be built this decade) has become a near-consensus,” Miles Brundage, an independent A.I. policy researcher who left OpenAI last year, told me recently.</p><p>Outside the Bay Area, few people have even heard of A.G.I., let alone started planning for it. And in my industry, journalists who take A.I. progress seriously still risk getting mocked as <a href="https://defector.com/not-enough-people-are-taking-the-wallet-inspector-seriously" title="" rel="noopener noreferrer" target="_blank">gullible dupes</a> or <a href="https://garymarcus.substack.com/p/ezra-kleins-new-take-on-agi-and-why" title="" rel="noopener noreferrer" target="_blank">industry shills</a>.</p><p>Honestly, I get the reaction. Even though we now have A.I. systems <a href="https://www.nytimes.com/2024/10/09/science/nobel-prize-chemistry.html" title="">contributing to Nobel Prize-winning breakthroughs</a>, and even though <a href="https://www.cnbc.com/2025/02/20/openai-tops-400-million-users-despite-deepseeks-emergence.html" title="" rel="noopener noreferrer" target="_blank">400 million people a week</a> are using ChatGPT, a lot of the A.I. that people encounter in their daily lives is a nuisance. I sympathize with people who see <a href="https://www.nytimes.com/2024/06/11/style/ai-search-slop.html" title="">A.I. slop</a> plastered all over their Facebook feeds, or have a clumsy interaction with a customer service chatbot and think: <em>This </em>is what’s going to take over the world?</p></div></div><div data-testid="companionColumn-4"><div><p>I used to scoff at the idea, too. But I’ve come to believe that I was wrong. A few things have persuaded me to take A.I. progress more seriously.</p><h3 id="link-4a4b7b6a"><span>The insiders are alarmed.</span></h3><p>The most disorienting thing about today’s A.I. industry is that the people closest to the technology — the employees and executives of the leading A.I. labs — tend to be the most worried about how fast it’s improving.</p><p>This is quite unusual. Back in 2010, when I was covering the rise of social media, nobody inside Twitter, Foursquare or Pinterest was warning that their apps could cause societal chaos. Mark Zuckerberg wasn’t testing Facebook to find evidence that it could be used to create novel bioweapons, or carry out autonomous cyberattacks.</p><p>But today, the people with the best information about A.I. progress — the people building powerful A.I., who have access to more-advanced systems than the general public sees — are telling us that big change is near. The leading A.I. companies are <a href="https://openai.com/safety/how-we-think-about-safety-alignment/" title="" rel="noopener noreferrer" target="_blank">actively preparing</a> for A.G.I.’s arrival, and are studying potentially scary properties of their models, such as whether they’re capable of <a href="https://www.axios.com/2024/12/13/ai-reasoning-models-scheme-skills" title="" rel="noopener noreferrer" target="_blank">scheming</a> and <a href="https://openai.com/index/chain-of-thought-monitoring/" title="" rel="noopener noreferrer" target="_blank">deception</a>, in anticipation of their becoming more capable and autonomous.</p><p>Sam Altman, the chief executive of OpenAI, has <a href="https://blog.samaltman.com/three-observations" title="" rel="noopener noreferrer" target="_blank">written</a> that “systems that start to point to A.G.I. are coming into view.”</p></div></div><div data-testid="companionColumn-5"><div><p>Demis Hassabis, the chief executive of Google DeepMind, <a href="https://www.bigtechnology.com/p/google-deepmind-ceo-demis-hassabis" title="" rel="noopener noreferrer" target="_blank">has said</a> A.G.I. is probably “three to five years away.”</p><p>Dario Amodei, the chief executive of Anthropic (who doesn’t like the term A.G.I. but agrees with the general principle), <a href="https://www.nytimes.com/2025/02/28/podcasts/hardfork-anthropic-dario-amodei.html" title="">told me last month</a> that he believed we were a year or two away from having “a very large number of A.I. systems that are much smarter than humans at almost everything.”</p></div></div><div data-testid="GridBlock-11"><div><div><picture id="grid-image-0-" data-credit="Massimo Berruti for The New York Times"><source srcset="https://static01.nyt.com/images/2025/03/12/multimedia/ROOSE-agi-1-02-czwm/ROOSE-agi-1-02-czwm-superJumbo.jpg?auto=webp&amp;quality=90" media="(min-width: 600px)"/><img alt="" src="https://static01.nyt.com/images/2025/03/12/multimedia/ROOSE-agi-1-02-czwm/ROOSE-agi-1-02-czwm-mobileMasterAt3x.jpg?auto=webp&amp;quality=90"/></picture><picture id="grid-image-1-" data-credit="Haiyun Jiang for The New York Times"><source srcset="https://static01.nyt.com/images/2025/03/12/multimedia/ROOSE-agi-1-03-czwm/ROOSE-agi-1-03-czwm-superJumbo.jpg?auto=webp&amp;quality=90" media="(min-width: 600px)"/><img alt="" src="https://static01.nyt.com/images/2025/03/12/multimedia/ROOSE-agi-1-03-czwm/ROOSE-agi-1-03-czwm-mobileMasterAt3x.jpg?auto=webp&amp;quality=90"/></picture><picture id="grid-image-2-" data-credit="Chloe Ellingson for The New York Times"><source srcset="https://static01.nyt.com/images/2025/03/12/multimedia/ROOSE-agi-1-05-czwm/ROOSE-agi-1-05-czwm-superJumbo.jpg?auto=webp&amp;quality=90" media="(min-width: 600px)"/><img alt="" src="https://static01.nyt.com/images/2025/03/12/multimedia/ROOSE-agi-1-05-czwm/ROOSE-agi-1-05-czwm-mobileMasterAt3x.jpg?auto=webp&amp;quality=90"/></picture><picture id="grid-image-3-" data-credit="Toby Melville/Reuters"><source srcset="https://static01.nyt.com/images/2025/03/12/multimedia/ROOSE-AGI-hassabis-2-lqmg/ROOSE-AGI-hassabis-2-lqmg-superJumbo.jpg?auto=webp&amp;quality=90" media="(min-width: 600px)"/><img alt="" src="https://static01.nyt.com/images/2025/03/12/multimedia/ROOSE-AGI-hassabis-2-lqmg/ROOSE-AGI-hassabis-2-lqmg-mobileMasterAt3x.jpg?auto=webp&amp;quality=90"/></picture></div><figcaption><span>Clockwise from top left, Dario Amodei, the chief executive of Anthropic; Sam Altman, the chief executive of OpenAI; Demis Hassabis, the chief executive of Google DeepMind; and Geoffrey Hinton, a pioneering A.I. researcher.</span><span><span>Credit...</span><span>Massimo Berruti for The New York Times; Haiyun Jiang for The New York Times; Chloe Ellingson for The New York Times; Toby Melville/Reuters</span></span></figcaption></div></div><div data-testid="companionColumn-6"><div><p>Maybe we should discount these predictions. After all, A.I. executives stand to profit from inflated A.G.I. hype, and might have incentives to exaggerate.</p><p>But lots of independent experts — including <a href="https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html" title="">Geoffrey Hinton</a> and <a href="https://yoshuabengio.org/2024/07/09/reasoning-through-arguments-against-taking-ai-safety-seriously/" title="" rel="noopener noreferrer" target="_blank">Yoshua Bengio</a>, two of the world’s most influential A.I. researchers, and <a href="https://www.nytimes.com/2025/03/04/opinion/ezra-klein-podcast-ben-buchanan.html" title="">Ben Buchanan</a>, who was the Biden administration’s top A.I. expert — are saying similar things. So are a host of other prominent <a href="https://time.com/6966882/economist-ai-transformation-society-anton-korinek/" title="" rel="noopener noreferrer" target="_blank">economists</a>, <a href="https://unlocked.microsoft.com/ai-anthology/terence-tao/" title="" rel="noopener noreferrer" target="_blank">mathematicians</a> and <a href="https://www.axios.com/2025/01/18/biden-sullivan-ai-race-trump-china" title="" rel="noopener noreferrer" target="_blank">national security officials</a>.</p></div></div><div data-testid="companionColumn-7"><div><p>To be fair, <a href="https://www.nature.com/articles/d41586-025-00649-4" title="" rel="noopener noreferrer" target="_blank">some experts</a> doubt that A.G.I. is imminent. But even if you ignore everyone who works at A.I. companies, or has a vested stake in the outcome, there are still enough credible independent voices with short A.G.I. timelines that we should take them seriously.</p><h3 id="link-4d0bbe20"><span>The A.I. models keep getting better.</span></h3><p>To me, just as persuasive as expert opinion is the evidence that today’s A.I. systems are improving quickly, in ways that are fairly obvious to anyone who uses them.</p><p>In 2022, when OpenAI released ChatGPT, the leading A.I. models struggled with basic arithmetic, frequently failed at complex reasoning problems and often “hallucinated,” or made up nonexistent facts. Chatbots from that era could do impressive things with the right prompting, but you’d never use one for anything critically important.</p><p>Today’s A.I. models are much better. Now, specialized models are putting up <a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/" title="" rel="noopener noreferrer" target="_blank">medalist-level scores</a> on the International Math Olympiad, and general-purpose models have gotten so good at complex problem solving that we’ve had to <a href="https://www.nytimes.com/2025/01/23/technology/ai-test-humanitys-last-exam.html" title="">create new, harder tests</a> to measure their capabilities. Hallucinations and factual mistakes still happen, but they’re rarer on newer models. And many businesses now trust A.I. models enough to build them into core, customer-facing functions.</p><p>(The New York Times has <a href="https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html" title="">sued</a> OpenAI and its partner, Microsoft, accusing them of copyright infringement of news content related to A.I. systems. OpenAI and Microsoft have denied the claims.)</p></div></div><div data-testid="companionColumn-8"><div><p>Some of the improvement is a function of scale. In A.I., bigger models, trained using more data and processing power, tend to produce better results, and today’s leading models are significantly bigger than their predecessors.</p><p>But it also stems from breakthroughs that A.I. researchers have made in recent years — most notably, the advent of “reasoning” models, which are built to take an additional computational step before giving a response.</p><p>Reasoning models, which include OpenAI’s o1 and DeepSeek’s R1, are trained to work through complex problems, and are built using reinforcement learning — a technique that was used to teach A.I. to <a href="https://deepmind.google/research/breakthroughs/alphago/" title="" rel="noopener noreferrer" target="_blank">play the board game Go</a> at a superhuman level. They appear to be succeeding at things that tripped up previous models. (Just one example: GPT-4o, a standard model released by OpenAI, scored 9 percent on AIME 2024, a set of extremely hard competition math problems; o1, a reasoning model that OpenAI <a href="https://openai.com/index/learning-to-reason-with-llms/" title="" rel="noopener noreferrer" target="_blank">released</a> several months later, scored 74 percent on the same test.)</p></div></div><div data-testid="DiptychBlock-17"><div><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><div data-testid="lazy-image"></div></div><figcaption data-testid="photoviewer-children-caption"><span>DeepSeek’s R1 model.</span><span><span>Credit...</span><span><span aria-hidden="false">Violeta Santos Moura/Reuters</span></span></span></figcaption></figure></div><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><div data-testid="lazy-image"></div></div><figcaption data-testid="photoviewer-children-caption"><span>OpenAI’s GPT-4o model.</span><span><span>Credit...</span><span><span aria-hidden="false">Arsenii Vaselenko for The New York Times</span></span></span></figcaption></figure></div></div></div><div data-testid="companionColumn-9"><p>As these tools improve, they are becoming useful for many kinds of white-collar knowledge work. My colleague Ezra Klein <a href="https://www.nytimes.com/2025/03/04/opinion/ezra-klein-podcast-ben-buchanan.html" title="">recently wrote</a> that the outputs of ChatGPT’s Deep Research, a premium feature that produces complex analytical briefs, were “at least the median” of the human researchers he’d worked with.</p></div><div data-testid="companionColumn-10"><div><p>I’ve also found many uses for A.I. tools in my work. I don’t use A.I. to write my columns, but I use it for lots of other things — preparing for interviews, summarizing research papers, building <a href="https://www.nytimes.com/2025/02/27/technology/personaltech/vibecoding-ai-software-programming.html" title="">personalized apps</a> to help me with administrative tasks. None of this was possible a few years ago. And I find it implausible that anyone who uses these systems regularly for serious work could conclude that they’ve hit a plateau.</p><p>If you really want to grasp how much better A.I. has gotten recently, talk to a programmer. A year or two ago, A.I. coding tools existed, but were aimed more at speeding up human coders than at replacing them. Today, software engineers tell me that A.I. does most of the actual coding for them, and that they increasingly feel that their job is to supervise the A.I. systems.</p><p>Jared Friedman, a partner at Y Combinator, a start-up accelerator, <a href="https://techcrunch.com/2025/03/06/a-quarter-of-startups-in-ycs-current-cohort-have-codebases-that-are-almost-entirely-ai-generated/" title="" rel="noopener noreferrer" target="_blank">recently said</a> a quarter of the accelerator’s current batch of start-ups were using A.I. to write nearly all their code.</p><p>“A year ago, they would’ve built their product from scratch — but now 95 percent of it is built by an A.I.,” he said.</p><h3 id="link-5116658"><span>Overpreparing is better than underpreparing.</span></h3><p>In the spirit of epistemic humility, I should say that I, and many others, could be wrong about our timelines.</p></div></div><div data-testid="companionColumn-11"><div><p>Maybe A.I. progress will hit a bottleneck we weren’t expecting — an energy shortage that prevents A.I. companies from building bigger data centers, or limited access to the powerful chips used to train A.I. models. Maybe today’s model architectures and training techniques can’t take us all the way to A.G.I., and more breakthroughs are needed.</p><p>But even if A.G.I. arrives a decade later than I expect — in 2036, rather than 2026 — I believe we should start preparing for it now.</p><p>Most of the advice I’ve heard for how institutions should prepare for A.G.I. boils down to things we should be doing anyway: modernizing our energy infrastructure, hardening our cybersecurity defenses, speeding up the approval pipeline for A.I.-designed drugs, writing regulations to prevent the most serious A.I. harms, teaching A.I. literacy in schools and prioritizing social and emotional development over soon-to-be-obsolete technical skills. These are all sensible ideas, with or without A.G.I.</p><p>Some tech leaders worry that premature fears about A.G.I. will cause us to regulate A.I. too aggressively. But the Trump administration has signaled that it wants to <a href="https://www.nytimes.com/2025/02/11/world/europe/vance-speech-paris-ai-summit.html" title="">speed up A.I. development</a>, not slow it down. And enough money is being spent to create the next generation of A.I. models — hundreds of billions of dollars, with more on the way — that it seems unlikely that leading A.I. companies will pump the brakes voluntarily.</p><p>I don’t worry about individuals overpreparing for A.G.I., either. A bigger risk, I think, is that most people won’t realize that powerful A.I. is here until it’s staring them in the face — eliminating their job, ensnaring them in a scam, harming them or someone they love. This is, roughly, what happened during the social media era, when we failed to recognize the risks of tools like Facebook and Twitter until they were too big and entrenched to change.</p></div></div><div data-testid="companionColumn-12"><div><p>That’s why I believe in taking the possibility of A.G.I. seriously now, even if we don’t know exactly when it will arrive or precisely what form it will take.</p><p>If we’re in denial — or if we’re simply not paying attention — we could lose the chance to shape this technology when it matters most.</p></div></div></section><div><div><div><div><p>Kevin Roose is a Times technology columnist and a host of the podcast &#34;<a href="https://www.nytimes.com/column/hard-fork">Hard Fork</a>.&#34;<span> </span></p></div></div></div><div><p>See more on: <a href="https://www.nytimes.com/topic/anthropic-ai-llc">Anthropic AI LLC</a>, <a href="https://www.nytimes.com/topic/openai">OpenAI</a>, <a href="https://www.nytimes.com/topic/sam-altman">Sam Altman</a>, <a href="https://www.nytimes.com/topic/dario-amodei">Dario Amodei</a>, <a href="https://www.nytimes.com/topic/geoffrey-e-hinton">Geoffrey E Hinton</a></p></div><div role="toolbar" data-testid="share-tools" aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count"><p><span><div><svg aria-hidden="true" width="21" height="18" viewBox="0 0 21 18"><path d="m14.52 17.831-5.715-4.545H2.4a1.468 1.468 0 0 1-1.468-1.469V1.894A1.471 1.471 0 0 1 2.4.405h16.583a1.469 1.469 0 0 1 1.469 1.469v9.923a1.469 1.469 0 0 1-1.47 1.47H14.58l-.06 4.564ZM2.4 1.645a.228.228 0 0 0-.228.229v9.923a.228.228 0 0 0 .228.229h6.811l4.06 3.235v-3.235h5.652a.228.228 0 0 0 .229-.229V1.874a.228.228 0 0 0-.229-.229H2.4Z" fill="#121212" fill-rule="nonzero"></path></svg><p><span><a href="https://www.hltv.org/2025/03/14/technology/why-im-feeling-the-agi.html">549</a></span></p></div></span></p><div data-testid="share-tools-menu"><ul data-testid="share-tools-list"><li><div></div></li><li><div></div></li><li></li><li><span><div><svg aria-hidden="true" width="21" height="18" viewBox="0 0 21 18"><path d="m14.52 17.831-5.715-4.545H2.4a1.468 1.468 0 0 1-1.468-1.469V1.894A1.471 1.471 0 0 1 2.4.405h16.583a1.469 1.469 0 0 1 1.469 1.469v9.923a1.469 1.469 0 0 1-1.47 1.47H14.58l-.06 4.564ZM2.4 1.645a.228.228 0 0 0-.228.229v9.923a.228.228 0 0 0 .228.229h6.811l4.06 3.235v-3.235h5.652a.228.228 0 0 0 .229-.229V1.874a.228.228 0 0 0-.229-.229H2.4Z" fill="#121212" fill-rule="nonzero"></path></svg><p><span><a href="https://www.hltv.org/2025/03/14/technology/why-im-feeling-the-agi.html">549</a></span></p></div></span></li></ul></div></div></div><div><div><section id="styln-guide" role="complementary" aria-labelledby="styln-guide-title"><hr/><h2 id="styln-guide-title">Explore Our Coverage of Artificial Intelligence</h2><hr/><p><strong>News</strong><strong> and Analysis</strong></p><ul><li><p><strong>Turing Award: </strong>The award, often called the Nobel Prize of computing, was given to Andrew Barto and Richard Sutton, the developers of a technique called reinforcement learning that is <a href="https://www.nytimes.com/2025/03/05/technology/turing-award-andrew-barto-richard-sutton.html">vital to chatbots</a>.</p></li><li><p><strong>Nvidia’s Profit Jumps:</strong> The company, which dominates the market for chips needed to build A.I. systems, said <a href="https://www.nytimes.com/2025/02/26/technology/nvidia-quarterly-earnings.html">revenue was up 78 percent from a year earlier</a>.</p></li><li><p><strong>GPT-4.5: </strong>OpenAI’s new technology signifies the end of an era. The company said it would be the <a href="https://www.nytimes.com/2025/02/27/technology/openai-artificial-intelligence-technology.html">last version of its chatbot system that did not do “chain-of-thought reasoning</a>.”</p></li><li><p><strong>Alexa Gets an Update: </strong>Amazon said it was giving Alexa an update powered by generative artificial intelligence, called Alexa+. It is said to <a href="https://www.nytimes.com/2025/02/26/technology/amazon-alexa-plus-generative-ai.html">make the virtual assistant more conversational and helpful</a>.</p></li></ul><hr/><p><strong>The Age of A.I.</strong></p><ul><li><p><strong>Human Therapists Prepare: </strong>The nation’s largest association of psychologists warned federal regulators that A.I. chatbots “masquerading” as therapists <a href="https://www.nytimes.com/2025/02/24/health/ai-therapists-chatbots.html">could drive vulnerable people to harm themselves or others</a>.</p></li><li><p><strong>DeepSeek:</strong> The Chinese start-up built one of the most powerful A.I. systems using far fewer computer chips than many experts thought possible. <a href="https://www.nytimes.com/2025/02/12/technology/deepseek-ai-chip-costs.html">Here’s a guide to how it succeeded</a>.</p></li></ul></section></div></div><div id="bottom-sheet-sensor"></div><div><div id="bottom-wrapper"><p>Advertisement</p><p><a href="#after-bottom">SKIP ADVERTISEMENT</a></p></div></div></article></div></div></div>
  </body>
</html>
