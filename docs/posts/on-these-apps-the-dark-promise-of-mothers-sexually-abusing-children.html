<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>On These Apps, the Dark Promise of Mothers Sexually Abusing Children | Khanh's feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nytimes.com/2024/12/07/us/child-abuse-apple-google-apps.html">Original</a>
    <h1>On These Apps, the Dark Promise of Mothers Sexually Abusing Children</h1>
    
    <div id="readability-page-1" class="page"><article id="story"><header><p id="article-summary">Smartphone apps downloaded from Apple and Google can allow parents and other abusers to connect with pedophiles who pay to watch — and direct — criminal behavior.</p><section data-testid="inline-interactive" id="mom-daughter-apps-topart" data-id="100000009863272" data-source-id="100000009863272"><div slug="mom-daughter-apps-topart" data-sourceid="100000009863272" id="embed-id-100000009863272">
      
    <!-- birdkit: do not modify this file -->

	
		
		
		
		
		
		
		
		
		
		
		
		
		


		<div id="g-2024-12-02-mom-daughter-apps" data-preview-slug="2024-12-02-mom-daughter-apps" data-birdkit-hydrate="564466d4ae49a036">	
			
	  <div><figure>  <div><div> <div><div> <p>Child abuse on the app</p> <p>i guess its an app that you can do live streams and stuff and i understand a lot of this app is considered 18+ but if minors are being involved and exploited then thats an issue. I was under the impression this was an app for live streams that entertainers/ comedy influencers go on but ive seen not many talk about the very weird side of the app.</p> </div><div> <p>Nope</p> <p>I have found people willing to serve there children on here for sexually acts on here so don&#39;t buy it they say it&#39;s free to download but this app could cost you some serious money please watch out if you do decide to get it I spent almost 50 to 60 dollars one time before I realized it was a scam</p> </div><div> <p>Not safe</p> <p>There are a lot of underage users on the app, and it doesn&#39;t feel safe navigating it as an adult, and I wish the creators of the app would regulate who can and cannot sign up</p> </div><div> <p>Sexy chat</p> <p>This app is DANGEROUS. It&#39;s a pedophiles haven.</p> </div><div> <p>Child abuse on the app</p> <p>i guess its an app that you can do live streams and stuff and i understand a lot of this app is considered 18+ but if minors are being involved and exploited then thats an issue. I was under the impression this was an app for live streams that entertainers/ comedy influencers go on but ive seen not many talk about the very weird side of the app.</p> </div></div></div> </div>  </figure><figure>  <div><div> <div><div> <p>Human trafficking</p> <p>I have come to understand that this app is connected to a human trafficking ring. Many of the people say they need help and are also unable to clearly communicate with the viewer in order to receive help. Don&#39;t download this app. Don&#39;t feed the machine.</p> </div><div> <p>Illegal content</p> <p>Porn with children they should be in prison shame on these demons</p> </div><div> <p>Let&#39;s be honest, why are there kids on here?</p> <p>Your app is littered with underage children who are exploited. I will be letting anyone and everyone know your app is disgusting along with that fact l&#39;ve reported it. This app obviously is for sick people and kids.</p> </div><div> <p>Human trafficking</p> <p>I have come to understand that this app is connected to a human trafficking ring. Many of the people say they need help and are also unable to clearly communicate with the viewer in order to receive help. Don&#39;t download this app. Don&#39;t feed the machine.</p> </div><div> <p>Let&#39;s be honest, why are there kids on here?</p> <p>Your app is littered with underage children who are exploited. I will be letting anyone and everyone know your app is disgusting along with that fact l&#39;ve reported it. This app obviously is for sick people and kids.</p> </div></div></div> </div>  </figure><figure>  <div><div> <div><div> <p>App is geared towards kids!,,</p> <p>PLEASE MAKE SURE THIS APP IS NOT ON YOUR KIDS TABLETS!!!!!!!!!! DISGUSTING APP</p> </div><div> <p>Horrifying app</p> <p>I keep getting messages from adult type people asking me too talk too them and support them at all hours of the day and night if I wanted porn I would have gone to the site and signed up if you want hookers this is the sight for you</p> </div><div> <p>Horrible for kids under and older</p> <p>I was on a livestream and this man sent me a flash photo and it wouldn&#39;t let me report it because I already looked and now I am traumatized because of it</p> </div><div> <p>App is geared towards kids!,,</p> <p>PLEASE MAKE SURE THIS APP IS NOT ON YOUR KIDS TABLETS!!!!!!!!!! DISGUSTING APP</p> </div><div> <p>Not safe</p> <p>There are a lot of underage users on the app, and it doesn&#39;t feel safe navigating it as an adult, and I wish the creators of the app would regulate who can and cannot sign up</p> </div></div></div> </div> <div><div><p><!-- HTML_TAG_START -->Users warned of child exploitation in reviews of smartphone apps.<!-- HTML_TAG_END --></p></div> </div> </figure> </div> 
			
			
		

		</div>
		
</div></section><div><div><p><a href="https://www.nytimes.com/by/michael-h-keller"><img alt="Michael H. Keller" title="Michael H. Keller" src="https://static01.nyt.com/images/2019/10/07/reader-center/author-michael-h-keller/author-michael-h-keller-thumbLarge.png"/></a></p><div><p><a href="https://www.nytimes.com/by/michael-h-keller" itemprop="name">Michael H. Keller</a></p><p>Michael H. Keller has been investigating online child sexual abuse for five years and has focused the past year on parental involvement in the exploitation.</p></div></div></div><p><time datetime="2024-12-07T11:40:25-05:00"><span>Dec. 7, 2024</span><span>Updated <span>11:40 a.m. ET</span></span></time></p></header><section name="articleBody"><div data-testid="companionColumn-0"><div><p>The promotional photo showed a mother affectionately hugging and kissing her daughter. The girl, around 8 years old, smiled into the camera.</p><p>With a few swipes on their phones, men entered a livestream where they paid $150 to watch the mother sexually abuse the girl for 10 minutes.</p><p>The horrendous activity wasn’t hidden on some dark corner of the internet. It was available for anyone with an iPhone or Android to download from the Apple or Google app store.</p><p>The woman, who lives in Southeast Asia, promoted her livestream on Bigo Live, a video chat app where The New York Times viewed a screenshot of her profile early this year. When she was later contacted online by an undercover agent for the U.S. Department of Homeland Security — posing as a man interested in young girls — she directed him to another livestreaming app, where her pay-per-view sexual abuse had moved.</p></div></div><div data-testid="companionColumn-1"><div><p>Since last year, The Times has been investigating the world of parents who run accounts on Instagram and elsewhere for their underage daughters and who post or sell racy photos of the girls, in some cases <a href="https://www.nytimes.com/2024/11/10/us/child-influencer.html" title="">earning large sums of money</a>. The Times <a href="https://www.nytimes.com/2024/02/22/us/instagram-child-influencers.html" title="">reported in February</a> that many of the so-called mom-run social media accounts with the biggest reach were overwhelmingly followed by adult men, including pedophiles.</p><p>The livestream apps downloaded from Apple and Google illustrate an even darker aspect of the social media technology boom, particularly for children living in poverty in developing countries. There, with the ease of a smartphone, parents and other adults can connect with pedophiles in the United States and elsewhere who pay to watch — and direct — criminal behavior.</p></div></div><div data-testid="ImageBlock-3"><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcset="https://static01.nyt.com/images/2024/12/05/multimedia/00mom-daughter-apps-fgct/00mom-daughter-apps-fgct-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcset="https://static01.nyt.com/images/2024/12/05/multimedia/00mom-daughter-apps-fgct/00mom-daughter-apps-fgct-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcset="https://static01.nyt.com/images/2024/12/05/multimedia/00mom-daughter-apps-fgct/00mom-daughter-apps-fgct-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"/><img alt="Protesters in Santa hats holding signs that read: “All we want is safer devices for our kids.”" src="https://static01.nyt.com/images/2024/12/05/multimedia/00mom-daughter-apps-fgct/00mom-daughter-apps-fgct-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale" srcset="https://static01.nyt.com/images/2024/12/05/multimedia/00mom-daughter-apps-fgct/00mom-daughter-apps-fgct-articleLarge.jpg?quality=75&amp;auto=webp 600w,https://static01.nyt.com/images/2024/12/05/multimedia/00mom-daughter-apps-fgct/00mom-daughter-apps-fgct-jumbo.jpg?quality=75&amp;auto=webp 1024w,https://static01.nyt.com/images/2024/12/05/multimedia/00mom-daughter-apps-fgct/00mom-daughter-apps-fgct-superJumbo.jpg?quality=75&amp;auto=webp 2048w" sizes="((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 60vw, 100vw" uri="nyt://image/9d5a4535-b554-5c36-b0c1-c41280f16a0e" decoding="async" width="600" height="400"/></picture></div><figcaption data-testid="photoviewer-children-caption"><span>Child safety advocates demonstrated at the Apple Store this month in New York’s Grand Central Terminal.</span><span><span>Credit...</span><span><span aria-hidden="false">Jeenah Moon for The New York Times</span></span></span></figcaption></figure></div></div><div data-testid="companionColumn-2"><div><p>After confirming the authenticity of the Bigo livestreamer with the authorities, The Times searched the Apple and Google app stores for other video chat apps. Reporters identified a sample of more than 80 apps that advertised children before stopping the search. They later contacted Homeland Security Investigations, the government’s main law enforcement group for international exploitation, for comment.</p><p>The agency made the undercover agent available to answer questions, so long as he was not identified.</p></div></div><div data-testid="companionColumn-3"><div><p>The apps had not been a focus of the agency’s work, the agent said, but the criminal activity mirrored that on dating websites he had investigated. There, men search for women, typically in Southeast Asia, who charge to sexually abuse children on camera.</p><p>While mothers or other family members are the most common culprits, he said, other adults — including members of criminal organizations — sometimes arrange the abuse.</p><p>“The number one customer base paying for this abuse is in the United States,” the agent said. “It’s not like they are abused once a day. It’s 50 men getting 50 separate shows. They’ll wake up these kids in the middle of the night to be abused.”</p><p>The livestream apps follow different models. Some, like Bigo, are designed for a mainstream audience to watch dancers, gamers or other content creators. Viewers can reward streamers with in-app currency.</p><p>Others are geared toward men looking for sexual encounters, and users can pay by the minute for private video chats. Although Apple and Google ban pornography from their stores, The Times found apps that showed nude adults in sexual poses. Some apps had names like “18+ Live &amp; Video Chat,” “Adult Live Chat” and “Adult Calls, Love Chat.”</p></div></div><div data-testid="companionColumn-4"><div><p>Streamers of all kinds collect money from their broadcasts, and the owners of the apps also take a cut, as do Apple and Google. The two big tech companies typically collect between 15 and 30 percent as a fee for in-app purchases.</p><p>In statements to The Times, neither Apple nor Google addressed the issue of in-app purchases for illegal streaming. Both companies said they had zero tolerance for child sexual abuse material and had removed or suspended the flagged apps. Both companies said they required app developers to police user-generated content on their platforms.</p><p>“We’re constantly on guard for these kinds of violations which carry severe penalties including removal from the store and termination from our developer program,” Fred Sainz, an Apple spokesman, said. “Our App Review team works 24/7 to review every new app and app update to ensure it meets our quality and safety standards, including stringent requirements for apps with person-to-person interactions.”</p><p>Asked about The Times’s sample of offending apps, Mr. Sainz said a majority had been detected during the company’s standard review process, with an additional 20 taken down after an internal investigation in response to The Times’s findings.</p><p>Karl Ryan, a Google spokesman, said the company “did not immediately uncover” child sexual abuse material in the apps The Times had flagged, but it suspended them “out of an abundance of caution” while the apps’ developers were contacted. “We take this issue extremely seriously,” he said.</p></div></div><div data-testid="companionColumn-5"><div><p>Many of the apps on both platforms advertised sex shows or bestiality. The Apple App Store’s search recommendations also helped The Times surface some of the apps advertising children by suggesting sexual terms such as “x.x.x live.”</p><p>In response, the company changed its search recommendations to no longer suggest adult content, Mr. Sainz said.</p></div></div><div data-testid="ImageBlock-11"><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><div data-testid="lazy-image"></div></div><figcaption data-testid="photoviewer-children-caption"><span>Brig. Gen. Portia B. Manalad of the Philippine National Police said her agency had rescued more than 500 children over the last five years. Many children abused online live in the Philippines.</span><span><span>Credit...</span><span><span aria-hidden="false">Ezra Acayan for The New York Times</span></span></span></figcaption></figure></div></div><div data-testid="companionColumn-6"><div><p>One profile identified by The Times showed a woman in Vietnam offering “HOT VIDEO” and listed possible participants as two young sisters, a little girl, three little boys and a dog.</p><p>Another woman in Vietnam described sex acts she could perform along with an invitation to “see mother and daughter, son.” A woman in the Philippines advertised “lil&amp;Mom” and showed a preview video of a young girl. The profiles did not include abuse, which required payment to be viewed.</p></div></div><div data-testid="companionColumn-7"><div><p>The livestreaming of child sexual abuse is thought to be most common in the Philippines, though the data is limited. <a href="https://www.ijm.org.ph/" title="" rel="noopener noreferrer" target="_blank">International Justice Mission</a>, a global human rights organization with a program to protect minors in that country, commissioned a study last year that estimated <a href="https://www.ijm.org/studies/scale-of-harm-estimating-the-prevalence-of-trafficking-to-produce-child-sexual-exploitation-material-in-the-philippines" title="" rel="noopener noreferrer" target="_blank">nearly 500,000 Filipino children</a> were being abused in the creation of illegal imagery.</p><p>The country’s top law enforcement official for such crimes, Brig. Gen. Portia B. Manalad of the Philippine National Police, said that she was aware of the apps, and that the agency had rescued more than 500 children and arrested more than 200 perpetrators — mostly relatives, “usually the mother” — over the last five years.</p><p>“We are trying our best to find the victims,” she said.</p><p>In the United States, The Times found nearly 100 federal criminal cases over the past decade involving men paying to watch the livestreaming of child sexual abuse.</p><p>In October, a woman in South Dakota, Krystal Kay Bulin, was <a href="https://www.justice.gov/usao-sd/pr/rapid-city-woman-sentenced-eight-years-federal-prison-facilitating-live-broadcast-child" title="" rel="noopener noreferrer" target="_blank">sentenced to eight years</a> in prison after she moderated a chat room during sexually explicit livestreams involving a 16-year-old girl. Ms. Bulin, the girl’s temporary guardian, facilitated the livestreams on an app called BuzzCast to help pay for a speeding ticket, according to court records.</p><p>A Florida man, Christopher John Streeter, has been <a href="https://www.justice.gov/usao-mdfl/pr/florida-man-who-financed-and-patronized-child-sex-trafficking-ring-philippines" title="" rel="noopener noreferrer" target="_blank">serving life in prison</a> since 2021 after sending roughly $130,000 over a decade to people in the Philippines to direct the rape of children as young as 12.</p></div></div><div data-testid="companionColumn-8"><div><p>He paid a premium if the video depicted girls losing their virginity or suffering injuries because of the sexual violence. Court records show Mr. Streeter’s victims were particularly vulnerable “due to poverty and illness.”</p><p>As a result of that case, six abused girls were rescued by local authorities in conjunction with officers from Homeland Security Investigations. The undercover agent who spoke to The Times said such outcomes were especially gratifying because once a livestream session ends, the evidence often disappears.</p><p>“It’s a very difficult crime to investigate,” he said. “No one knows that it happened, except the poor kid that was raped, the mother that did it and the guy who paid for it.”</p><p>By some measures, online child sexual abuse has increased in recent years. The distribution of such material surged during the pandemic, according to <a href="https://web.archive.org/web/20240204130446/https://www.europol.europa.eu/cms/sites/default/files/documents/internet_organised_crime_threat_assessment_iocta_2020.pdf" title="" rel="noopener noreferrer" target="_blank">a study by Europol</a>, the European law enforcement agency. An investigator for the organization said rates had been elevated ever since.</p></div></div><div data-testid="companionColumn-9"><p>“Now, with these new livestreaming platforms and use of webcams, people can, from a relatively safe environment, abuse and direct the abuse of children from a distance in a very, very easy way,” said the investigator, Danny van Althuis.</p></div><div data-testid="ImageBlock-19"><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><div data-testid="lazy-image"></div></div><figcaption data-testid="photoviewer-children-caption"><span>Sarah Gardner leads a child safety advocacy group, the Heat Initiative.</span><span><span>Credit...</span><span><span aria-hidden="false">Jessica Pons for The New York Times</span></span></span></figcaption></figure></div></div><div data-testid="companionColumn-10"><div><p>Sarah Gardner, who leads a child safety advocacy group, <a href="https://www.nytimes.com/2023/09/01/technology/child-sex-abuse-imagery-apple-safety-privacy.html" title="">the Heat Initiative</a>, said The Times’s findings were particularly shocking given that Apple and Google both claim to hold apps on their marketplaces to the highest safety and content standards.</p><p>She faulted the two companies for allowing the livestreaming, and for facilitating and profiting from the payments.</p><p>“The most powerful companies in the world are enabling the sexual abuse of a child to be livestreamed on the internet,” she said. On Thursday, Ms. Gardner and others protested at Apple’s store in New York’s Grand Central Terminal, calling on the company to improve child safety.</p><p>The Times learned of the streaming on Bigo Live from a 39-year-old man in Utah who had visited the woman’s profile page on his iPhone in what he described as a period of suicidal depression. The man, who spoke on the condition of anonymity, paid $550 for the mother and another woman to sexually abuse their daughters, including the 8-year-old girl and another believed to be 3 or 4. Some of the payments were made through in-app tokens, but most of the money was transferred through PayPal, the man said.</p></div></div><div data-testid="companionColumn-11"><div><p>The man saved recordings of the sessions and reported them to the Canadian Center for Child Protection, which verified the abuse to The Times. He also reported the women to Bigo Live’s support staff, emails show.</p><p>A PayPal spokeswoman said the company worked with law enforcement around the world to help stop child exploitation.</p><p>Bigo Live said that when it received the report from the Utah man, “we took appropriate action against the creators involved, including account suspension and content removal.” In its statement, the company said it was “deeply committed to protecting user safety” and was “continuously improving our technology and procedures.”</p><p>When The Times searched for other smartphone apps with similar content, many were hiding in plain sight. In reviews posted to Apple’s and Google’s app stores, users warned of child exploitation on some apps.</p><p>Reviews for the apps Bigo Live, Gaze, Superlive and Tango mentioned parents sexually exploiting their children, according to an analysis by The Times and Brian Levine, a professor at the University of Massachusetts, Amherst, who has created <a href="https://www.nytimes.com/2023/08/10/business/sextortion-ai-app-danger-project-safety-reviews.html" title="">a database of app reviews</a> with Hany Farid, a professor at the University of California, Berkeley. (Some apps were also identified with help from Primal Wijesekera, a research scientist at the <a href="https://icsi.berkeley.edu/icsi/about" title="" rel="noopener noreferrer" target="_blank">International Computer Science Institute</a>, where he maintains searchable records of the app stores.)</p></div></div><div data-testid="companionColumn-12"><div><p>“Women use kids in their streams to promote child X and BIGO just let’s it happen. Do not, repeat, do not download this disgusting app,” one user wrote on the Apple App Store, using an abbreviation for “child exploitation.”</p><p>“I have found people willing to serve there children on here,” one user wrote about Gaze.</p><p>BuzzCast and Superlive did not respond to requests for comment. Representatives for Gaze and Tango said their companies had no tolerance for child sexual abuse material and pointed to multiple moderation systems they used to enforce their standards. They said that they took user reviews seriously, and also that the negative reviews were unrepresentative and may have been written by competitors.</p><p>“We are deeply committed to ensuring the safety of our platform,” said Dor Isseroff, chief operating officer of Tango, adding that he was confident the app was not used to stream abuse, though some users were advertising the activity on other platforms. He said the company used information from the accounts The Times discovered to upgrade its moderation systems, and on Friday “identified and suspended dozens of profiles that violated our guidelines.”</p><p>Quantifying the illegal activity is difficult, but it has become prevalent enough that Homeland Security last year <a href="https://www.dhs.gov/sites/default/files/2023-04/23_0420_plcy_2023-qhsr.pdf" title="" rel="noopener noreferrer" target="_blank">added</a> “crimes of exploitation,” which includes child sexual abuse, to its list of priorities, putting it on par with terrorism and border security.</p><p>Secretary of Homeland Security Alejandro N. Mayorkas said in an interview that he had been aware of the issue since serving in the Obama administration. The problem has only grown, he said.</p></div></div><div data-testid="companionColumn-13"><div><p>“I decided to lift its profile up and to devote the resources and attention accordingly,” Mr. Mayorkas said.</p><p>Government officials in the European Union, too, have been working to make it easier to combat the livestreaming of child sexual abuse, which has been made difficult by differing laws. <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_24_631" title="" rel="noopener noreferrer" target="_blank">A proposal</a> would update the bloc’s criminal code to facilitate cross-border investigations.</p><p>In June, Homeland Security organized an <a href="https://www.dhs.gov/hsi/news/2024/07/02/hsi-europol-joint-operation-generates-197-new-leads-criminal-buyers-child-sex-abuse" title="" rel="noopener noreferrer" target="_blank">investigative “sprint”</a> with Europol, in which officials from 10 countries shared data from various investigations. It generated leads on nearly 200 “criminal buyers,” a Europol spokeswoman said.</p><p>While the livestreaming apps may be relatively new to many authorities, they have been around for years. Many of the apps launched during the pandemic, when interest in live video surged. On the dark web, they have also been a topic of interest, according to the Canadian Center for Child Protection, which monitors such activity.</p><p>In one post mentioning Tango in January, a user shared a screenshot of a young girl and inquired: “Can anyone share the videos of this cutie who shows and masturbates along with her sister and mother in other videos?”</p></div></div><div data-testid="companionColumn-14"><div><p>During 13 years working undercover, the Homeland Security agent said, he had helped rescue 286 children. He said the woman in the Southeast Asia case had been identified and the agency was now working with local authorities to rescue the 8-year-old.</p><p>Next year, he will take part in <a href="https://www.dhs.gov/know2protect" title="" rel="noopener noreferrer" target="_blank">online safety education sessions for teenagers</a> and train more agents.</p><p>Still, he said, “we’ve probably infiltrated .0001 percent of the actual abuse that’s occurring.”</p><p>Jennifer Valentino-DeVries<!-- --> contributed reporting. Produced by <!-- -->Gray Beltran<!-- --> and <!-- -->Rumsey Taylor<!-- -->.</p></div></div></section><div><div><div><p>Michael H. Keller is a Times reporter who combines traditional reporting and computer programming. His work has examined technology’s impact on society and shortcomings of the criminal justice system.<span> </span></p></div></div></div></article></div>
  </body>
</html>
