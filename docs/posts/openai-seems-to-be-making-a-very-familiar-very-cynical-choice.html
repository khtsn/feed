<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>OpenAI Seems to Be Making a Very Familiar, Very Cynical Choice | Khanh's feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nytimes.com/2025/06/11/opinion/open-ai-big-tech-advertising.html">Original</a>
    <h1>OpenAI Seems to Be Making a Very Familiar, Very Cynical Choice</h1>
    
    <div id="readability-page-1" class="page"><article id="story"><header><p>Guest Essay</p><p><time datetime="2025-06-11T05:02:37-04:00">June 11, 2025</time></p><figure aria-label="media" role="group" data-testid="VideoBlock"><div><p><span>Video</span></p><div><div><p><img src="https://static01.nyt.com/images/2025/06/11/opinion/11vara-image-still/11vara-image-still-square640.jpg" data-testid="cinemagraph_image"/></p><video data-testid="cinemagraph" poster="https://static01.nyt.com/images/2025/06/11/opinion/11vara-image-still/11vara-image-still-square640.jpg" src="https://vp.nyt.com/video/2025/06/10/141835_1_11vara-image_wg_720p.mp4" muted="" loop="" autoplay="" playsinline=""></video></div></div></div><figcaption><span><span>Credit</span><span><span>Credit...</span><span>Illustration by Sam Whitney/The New York Times</span></span></span></figcaption></figure><div><div><div><p><a href="https://www.nytimes.com/by/vauhini-vara" itemprop="name">Vauhini Vara</a></p><div><p>Ms. Vara is a contributing writer at Bloomberg Businessweek<em> </em>and the author of “Searches: Selfhood in the Digital Age.”</p></div></div></div></div></header><section name="articleBody"><div data-testid="companionColumn-0"><div><p>Last spring, Sam Altman, the chief executive of OpenAI, sat in the chancel of Harvard Memorial Church, sermonizing against advertising. “I will disclose, just as a personal bias, that I hate ads,” <a href="https://www.youtube.com/watch?v=FVRHTWWEIz4&amp;t=2263s" title="" rel="noopener noreferrer" target="_blank">he began</a> in his usual calm cadence, one sneakered foot crossed onto his lap. He said that ads “fundamentally misalign a user’s incentives with the company providing the service,” adding that he found the notion of mixing advertising with artificial intelligence — the product his company is built on — “uniquely unsettling.”</p><p>The comment reminded me immediately of something I’d heard before, from around the time I was first getting online. It came from a <a href="http://infolab.stanford.edu/pub/papers/google.pdf" title="" rel="noopener noreferrer" target="_blank">seminal paper</a> that Sergey Brin and Larry Page wrote in 1998, when they were at Stanford developing Google. They argued that advertising often made search engines less useful, and that companies that relied on it would “be inherently biased towards the advertisers and away from the needs of the consumers.”</p><p>I showed up at Stanford as a freshman in 2000, not long after Mr. Brin and Mr. Page had accepted a $25 million round of venture capital funding to turn their academic project into a business. My best friend there persuaded me to try Google, describing it as more ethical than the search engines that had come before. What we didn’t realize was that in the midst of the dot-com crash, which coincided with our arrival, Google’s investors were pressuring the co-founders to hire a more experienced chief executive.</p><p>Mr. Brin and Mr. Page brought in Eric Schmidt, who in turn hired Sheryl Sandberg, the chief of staff to Lawrence H. Summers when he was Treasury secretary, to build an advertising program. Filing for Google to go public a couple of years later, Mr. Brin and Mr. Page explained away the reversal of their anti-advertising stance by <a href="https://abc.xyz/investor/founders-letters/ipo-letter/" title="" rel="noopener noreferrer" target="_blank">telling shareholders</a> that ads made Google more useful because they provided what the founders called “great commercial information.”</p></div></div><div data-testid="companionColumn-1"><div><p>My senior year, news filtered into The Stanford Daily, where I worked, that Facebook — which some of us had heard about from friends at Harvard, where it had started — was coming to our campus. “I know it sounds corny, but I’d love to improve people’s lives, especially socially,” Mark Zuckerberg, Facebook’s co-founder, <a href="https://archives.stanforddaily.com/2004/04/30?page=4&amp;section=MODSMD_ARTICLE8" title="" rel="noopener noreferrer" target="_blank">told The Daily’s reporter</a>. He added, “In the future we may sell ads to get the money back, but since providing the service is so cheap, we may choose not to do that for a while.”</p><p>Mr. Zuckerberg went on to quit Harvard and move to Palo Alto, Calif. I went on to The Wall Street Journal. Covering Facebook in 2007, I <a href="https://www.wsj.com/articles/SB118783296519606151" title="" rel="noopener noreferrer" target="_blank">got a scoop</a> that Facebook — which had in fact introduced ads — would begin using data from individual users and their “friends” on the site to sharpen how ads were targeted to them. Like Google before it, Facebook positioned this as being good for users. Mr. Zuckerberg even brought Ms. Sandberg over from Google to help. When an economic downturn, followed by an I.P.O., later put pressure on Facebook, it followed Google’s playbook: doubling down on advertising. In this case, it did so by collecting and monetizing even more personal information about its users.</p><p>Which brings me back to Mr. Altman and OpenAI, the parent company of ChatGPT. It started as a nonprofit with a stated mission to build A.I. that would benefit humanity. After several interim restructurings, OpenAI has now announced that it will <a href="https://www.nytimes.com/2025/05/06/business/dealbook/altman-openai-plan-b.html" title="">create a public benefit corporation</a> (albeit one still controlled by the nonprofit) to serve both the public good and shareholders’ needs, while removing a cap on investors’ returns — a change its chief financial officer, Sarah Friar, said “<a href="https://www.reuters.com/world/europe/openai-cfo-says-new-structure-opens-door-potential-future-ipo-2025-05-28/" title="" rel="noopener noreferrer" target="_blank">gets us to an I.P.O.-able event</a> … if and when we want to.” The prospect of an I.P.O. and <a href="https://www.nytimes.com/2025/06/06/business/economy/trump-tariffs-economy-uncertainty.html" title="">talk of an economic downturn</a>: the same conditions that preceded Google and Facebook’s turn to advertising.</p><p>The stage is set, then, for the next phase of Big Tech’s ever-deepening exploitation of the natural human desire for information, connection and well-being. It’s not surprising, in that context, that Mr. Altman and other OpenAI executives are gently floating the prospect of using advertising after all. In December, Ms. Friar <a href="https://www.ft.com/content/9350d075-1658-4d3c-8bc9-b9b3dfc29b26" title="" rel="noopener noreferrer" target="_blank">told The Financial Times</a> that OpenAI is considering it, though she clarified that the company has “no active plans” for ads. Mr. Altman <a href="https://stratechery.com/2025/an-interview-with-openai-ceo-sam-altman-about-building-a-consumer-tech-company/" title="" rel="noopener noreferrer" target="_blank">mused later</a> about an affiliate revenue model, by which his company would collect a percentage of sales whenever people bought something they discovered through an OpenAI feature called Deep Research. He added, “That would be cool.”</p><p>Mr. Altman specified that OpenAI wouldn’t accept money to change the placement of product mentions. Still, it’s not hard to imagine how a new OpenAI might work, combining all the personal information we already share with ChatGPT — marriage troubles, office conflicts — with the billions of words of text OpenAI consumed while building its products, in order to send us increasingly well-targeted recommendations about what to do with our time, money and attention.</p></div></div><div data-testid="companionColumn-2"><div><p>I doubt we would have to wait long for Mr. Altman to instruct us that this is for our own benefit. And once ChatGPT went there, it would be a given that everyone else would, too. Google, meanwhile, is <a href="https://searchengineland.com/google-ads-ai-overviews-ai-mode-desktop-455733" title="" rel="noopener noreferrer" target="_blank">already placing ads alongside its A.I.-generated search results</a>.</p><p>The problem isn’t just that this approach would turn digital tools supposedly designed to help users into digital tools designed to help advertisers — constituencies whose interests are not identical. It’s also that these tools would dramatically scale up what the scholar Shoshana Zuboff has labeled “surveillance capitalism”: an extensive system in which corporations treat our experiences and identities as commodities they can use to manipulate us through advertising. The effect, <a href="https://www.nytimes.com/2021/01/29/opinion/sunday/facebook-surveillance-society-technology.html" title="">she has argued</a>, is “a fundamentally anti-democratic epistemic coup” — a coup based on knowledge, not muscle — “marked by unprecedented concentrations of knowledge about us and the unaccountable power that accrues to such knowledge.” With the rise of A.I., the journalist Karen Hao, the author of “Empire of AI: Dreams and Nightmares in Sam Altman’s OpenAI,” wrote in a Times Opinion guest essay, tech companies “<a href="https://www.nytimes.com/2025/05/30/opinion/silicon-valley-ai-empire.html" title="">are growing into modern-day empires</a>.”</p><p>Roger McNamee, a former mentor to both Ms. Sandberg and Mr. Zuckerberg, as well as an early Facebook investor, had what he describes as “a front-row seat” during the early years of both Google and Facebook. He later became a critic of their surveillance of users and of what he sees as the failure of elected officials to require appropriate safeguards. Mr. McNamee recently told me that he’s not as close to OpenAI as he was to those other companies, “but my pattern recognition skills are better than they used to be.” He says the hazard this time around is greater, compounded by all the data A.I. companies have consumed, not to mention their intense drain on natural resources and their potential to threaten the livelihood of millions of workers — all for products he regards as having minimal value. If OpenAI embraces advertising and pivots to this kind of surveillance capitalism, he said, it would constitute a “five-alarm fire.”</p><p>Mr. Altman <a href="https://www.youtube.com/live/5MWT_doo68k?si=3Ogb9IZKnvWmLIAt&amp;t=1034" title="" rel="noopener noreferrer" target="_blank">recently claimed</a> that about 10 percent of the world uses the company’s products. That’s a lot for a company whose products have been publicly available for only a few years — but it also means that 90 percent of the world doesn’t. Some people are actively resisting A.I. products like ChatGPT and Google’s Gemini. They, like Mr. McNamee, have seen this movie before. This time, they can see what’s coming.</p></div></div><div data-testid="companionColumn-3"><div><p>Vauhini Vara is a contributing writer at Bloomberg Businessweek<em> </em>and the author of “Searches: Selfhood in the Digital Age.”</p><p>Source images by Dario Xavier and simonkr/Getty Images</p><p><em>The Times is committed to publishing </em><a href="https://www.nytimes.com/2019/01/31/opinion/letters/letters-to-editor-new-york-times-women.html" title=""><em>a diversity of letters</em></a><em> to the editor. We’d like to hear what you think about this or any of our articles. Here are some </em><a href="https://help.nytimes.com/hc/en-us/articles/115014925288-How-to-submit-a-letter-to-the-editor" title=""><em>tips</em></a><em>. And here’s our email: </em><a href="mailto:letters@nytimes.com" title=""><em>letters@nytimes.com</em></a><em>.</em></p><p><em>Follow the New York Times Opinion section on </em><a href="https://www.facebook.com/nytopinion" title="" rel="noopener noreferrer" target="_blank"><em>Facebook</em></a><em>, </em><a href="https://www.instagram.com/nytopinion/" title="" rel="noopener noreferrer" target="_blank"><em>Instagram</em></a><em>, </em><a href="https://www.tiktok.com/@nytopinion" title="" rel="noopener noreferrer" target="_blank"><em>TikTok</em></a><em>, </em><a href="https://bsky.app/profile/nytopinion.nytimes.com" title="" rel="noopener noreferrer" target="_blank"><em>Bluesky</em></a>, <a href="https://www.whatsapp.com/channel/0029VaN8tdZ5vKAGNwXaED0M" title="" rel="noopener noreferrer" target="_blank"><em>WhatsApp</em></a><em> and </em><a href="https://www.threads.net/@nytopinion" title="" rel="noopener noreferrer" target="_blank"><em>Threads</em></a><em>.</em></p></div></div></section><div><div><div><p>Vauhini Vara is a journalist, an editor and the author of “The Immortal King Rao,” a novel. <span> <a href="https://twitter.com/vauhinivara" rel="noopener noreferrer" target="_blank"><span>@</span>vauhinivara</a> </span></p></div></div></div></article></div>
  </body>
</html>
