<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Rethinking ‘Checks and Balances’ for the A.I. Age | Khanh's feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nytimes.com/2024/09/24/business/ai-democracy-government.html">Original</a>
    <h1>Rethinking ‘Checks and Balances’ for the A.I. Age</h1>
    
    <div id="readability-page-1" class="page"><div id="site-content"><div><article id="story"><header><p id="article-summary">A project at Stanford points to the need for institutional innovation, especially in government, to increase the odds that A.I. enhances democracy.</p><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="imageContainer-children-Image"><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcset="https://static01.nyt.com/images/2024/09/24/multimedia/24AI-papers-tfmw/24AI-papers-tfmw-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcset="https://static01.nyt.com/images/2024/09/24/multimedia/24AI-papers-tfmw/24AI-papers-tfmw-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcset="https://static01.nyt.com/images/2024/09/24/multimedia/24AI-papers-tfmw/24AI-papers-tfmw-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"/><img alt="" src="https://static01.nyt.com/images/2024/09/24/multimedia/24AI-papers-tfmw/24AI-papers-tfmw-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale" srcset="https://static01.nyt.com/images/2024/09/24/multimedia/24AI-papers-tfmw/24AI-papers-tfmw-articleLarge.jpg?quality=75&amp;auto=webp 600w,https://static01.nyt.com/images/2024/09/24/multimedia/24AI-papers-tfmw/24AI-papers-tfmw-jumbo.jpg?quality=75&amp;auto=webp 1024w,https://static01.nyt.com/images/2024/09/24/multimedia/24AI-papers-tfmw/24AI-papers-tfmw-superJumbo.jpg?quality=75&amp;auto=webp 2048w" sizes="((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 80vw, 100vw" decoding="async" width="600" height="436"/></picture></div><figcaption data-testid="photoviewer-children-ImageCaption"><span>The Stanford initiative focuses on A.I.’s threats to democracy and technology’s potential to revitalize democratic decision-making.</span><span><span>Credit...</span><span><span aria-hidden="false">Ben Margot/Associated Press</span></span></span></figcaption></figure></div><div><div><p><a href="https://www.nytimes.com/by/steve-lohr"><img alt="Steve Lohr" title="Steve Lohr" src="https://static01.nyt.com/images/2018/02/20/multimedia/author-steve-lohr/author-steve-lohr-thumbLarge-v3.png"/></a></p></div></div><p><time datetime="2024-09-24T08:42:12-04:00"><span>Sept. 24, 2024</span><span>Updated <span>8:42 a.m. ET</span></span></time></p></header><section name="articleBody"><div data-testid="companionColumn-0"><div><p>In the late 1780s, shortly after the Industrial Revolution had begun, Alexander Hamilton, James Madison and John Jay wrote a series of 85 spirited essays, collectively known as the Federalist Papers. They argued for ratification of the Constitution and an American system of checks and balances to keep power-hungry “factions” in check.</p><p>A new project, orchestrated by Stanford University and published on Tuesday, is inspired by the Federalist Papers and contends that today is a broadly similar historical moment of <a href="https://www.nytimes.com/2023/06/10/business/ai-jobs-work.html" title="">economic and political upheaval</a> that calls for a rethinking of society’s institutional arrangements.</p><p>In an introduction to its collection of 12 essays, <a href="https://www.digitalistpapers.com/" title="" rel="noopener noreferrer" target="_blank">called the Digitalist Papers</a>, the editors overseeing the project, including Erik Brynjolfsson, director of the Stanford Digital Economy Lab, and Condoleezza Rice, secretary of state in the George W. Bush administration and director of the Hoover Institution, identify their overarching concern.</p><p>“A powerful new technology, artificial intelligence,” they write, “explodes onto the scene and <a href="https://www.nytimes.com/2024/09/16/business/china-ai-safety.html" title="">threatens to transform</a>, for better or worse, all legacy social institutions.”</p></div></div><div data-testid="companionColumn-1"><div><p>The most common theme in the diverse collection of essays: Citizens need to be more involved in determining how to regulate and incorporate A.I. into their lives. “To build A.I. for the people, with the people,” as one essay summed it up.</p><p>The project is being published as the technology is racing ahead. A.I. enthusiasts see a future of <a href="https://www.nytimes.com/2024/04/01/business/economy/artificial-intelligence-productivity.html" title="">higher economic growth</a>, increased prosperity and a <a href="https://www.nytimes.com/2024/08/26/climate/ai-planet-climate-change.html" title="">faster pace of scientific discovery</a>. But the technology is also raising fears of a <a href="https://www.nytimes.com/2023/05/16/technology/openai-altman-artificial-intelligence-regulation.html" title="">dystopian alternative</a> — A.I. chatbots and automated software not only replacing millions of workers, but also generating limitless misinformation and worsening political polarization. How to govern and guide A.I. in the public interest remains an open question.</p><p>“Technologists are pushing the A.I. frontier, and that’s great,” said Mr. Brynjolfsson, who initiated the project. “But there’s been no comparable effort given to the institutional innovation needed for this technology to be used less to fuel misinformation and polarization, and more to empower people more broadly.”</p></div></div><div data-testid="ImageBlock-3"><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><div data-testid="lazy-image"></div></div><figcaption data-testid="photoviewer-children-caption"><span>Condoleezza Rice, right, a former secretary of state and current director of the Hoover Institution at Stanford, is among the editors of the Digitalist Papers.</span><span><span>Credit...</span><span><span aria-hidden="false">Julia Nikhinson/Associated Press</span></span></span></figcaption></figure></div></div><div data-testid="companionColumn-2"><p>By now, many governments, nonprofits and universities and even a few companies have recommended <a href="https://www.nytimes.com/2024/08/14/technology/ai-california-bill-silicon-valley.html" title="">A.I. guidelines and guardrails</a>, typically a list of dos and don’ts. The Stanford initiative, subtitled “Artificial Intelligence and Democracy in America,” has a different focus, not so much prescriptive solutions as different perspectives on the A.I. threats to democracy and technology’s potential to revitalize democratic decision-making.</p></div><div data-testid="companionColumn-3"><div><p>The project’s five editors and 19 essay authors and co-authors span different disciplines and outlooks — economists, political scientists and technologists, liberals and conservatives. Two pillars of the Silicon Valley establishment were invited to contribute essays: Reid Hoffman, co-founder of LinkedIn and a venture capitalist, and Eric Schmidt, former chief executive of Google.</p><p>Support in funding and staff time for the Digitalist Papers came from Stanford and the Project Liberty Institute, a nonprofit focused on fostering a more human-centered internet.</p><p>Most of the Stanford project’s authors share a concern that the economic power of the big tech companies will increasingly result in political power. The essays also look at how to let citizens and consumers, rather than lobbyists and big tech companies, shape A.I. policy.</p><p>“The potential for democratic innovation is there, but the current political economy, shaped by moneyed interests and polarization, does not allow change,” said Lawrence Lessig, a professor at Harvard Law School.</p><p>One potential avenue to address the problem is what he calls “protected democratic deliberation” — where some issues can be debated and moved along outside the legacy political process.</p></div></div><div data-testid="companionColumn-4"><div><p>Mr. Lessig points to the work of “citizen assemblies” in Ireland. Same-sex marriage and abortion were politically off-limits for the Irish Parliament, given the influence of the Roman Catholic Church. Citizen assemblies were freer to debate those issues. They came up with positions that the public overwhelmingly ratified in referendums to legalize same-sex marriage and abortion.</p><p>Taiwan is cited repeatedly in the essays as a leader in the practice of digitally enabled outreach to citizens to solicit their views on a range of subjects.</p><p>The issues tackled by citizens there have included the rules for admitting Uber to compete with local taxi companies and setting priorities to shape A.I. policy.</p><p>Taiwan uses what it calls “alignment assemblies,” soliciting the ideas and views of thousands of randomly selected citizens. One such assembly on misinformation online this year helped influence anti-fraud legislation that includes stronger reporting and disclosure requirements for big tech social networks.</p><p>A key to Taiwan’s success, said Saffron Huang, co-founder of the Collective Intelligence Project, which has worked with the Taiwanese government, is that the citizen views have repeatedly been translated into policy actions, which has built trust in the process.</p></div></div><div data-testid="companionColumn-5"><p>Audrey Tang, Taiwan’s founding digital minister, said the online forums could be “a very effective way for citizens to contribute to the agenda and guide the trajectory of technology policy instead of the brakes and pedals of traditional regulation.”</p></div><div data-testid="ImageBlock-11"><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><div data-testid="lazy-image"></div></div><figcaption data-testid="photoviewer-children-caption"><span>Audrey Tang, the first digital minister of Taiwan.</span><span><span>Credit...</span><span><span aria-hidden="false">I-Hwa Cheng for The New York Times</span></span></span></figcaption></figure></div></div><div data-testid="companionColumn-6"><div><p>The conservative contributors to the project also see a strong ecosystem of civic and other independent institutions — like those in Taiwan — as crucial counterweights to the rising power of the big tech companies. But they regard them as players in a marketplace for ideas best left free of most government controls.</p><p>“It is A.I. regulation, not A.I., that threatens democracy,” writes John H. Cochrane, a senior fellow at the Hoover Institution.</p><p>The main danger, Mr. Cochrane said, is having a government or corporate bureaucracy decide what is and is not appropriate speech. “We’re talking about censorship,” he said.</p></div></div><div data-testid="companionColumn-7"><div><p>Regulation, Mr. Cochrane said, should come after abuses become clear instead of pre-emptively setting rules. Who in 2004, when Facebook was founded, could have predicted the problems coming with social networks harming teenage girls in particular?</p><p>“It’s a process of constant learning and reform,” Mr. Cochrane said. “Bit by bit, in a contentious democracy, that’s how we figure out what to do.”</p><p>After the publication of the project, its organizers, including Ms. Rice and Mr. Brynjolfsson, plan to meet with policymakers and make presentations. Their goal, they say, is to encourage analysis and debate, and begin to build a case for optimism.</p><p>“We can build new systems of governance and guide technological development with an eye toward supporting and even enhancing democratic principles, rather than undermining them,” the editors wrote.</p></div></div></section><div><div><div><p>Steve Lohr writes about technology and its impact on the economy, jobs and the workplace.<span> <a href="https://www.nytimes.com/by/steve-lohr">More about Steve Lohr</a></span></p></div></div></div><div><div><section id="styln-guide" role="complementary" aria-labelledby="styln-guide-title"><hr/><h2 id="styln-guide-title">Explore Our Coverage of Artificial Intelligence</h2><hr/><p><strong>News</strong><strong> and Analysis</strong></p><ul><li><p>California will now <a href="https://www.nytimes.com/2024/09/17/technology/california-deepfakes-law-social-media-newsom.html">require social media companies to moderate</a> the spread of election-related impersonations powered by A.I., known as “deepfakes,” after Gov. Gavin Newsom, a Democrat, signed three new laws on the subject.</p></li><li><p>Scientists who helped pioneer A.I. are warning that countries <a href="https://www.nytimes.com/2024/09/16/business/china-ai-safety.html">must create a global system of oversight</a> to check the potentially grave risks posed by the fast-developing technology.</p></li><li><p>OpenAI is in <a href="https://www.nytimes.com/2024/09/11/technology/openai-fund-raising-valuation.html">talks to raise about $6.5 billion</a> as part of a deal that would value the company in the vicinity of $150 billion, a nearly $70 billion increase from its valuation nine months ago.</p></li></ul><hr/><p><strong>The Age of A.I.</strong></p><ul><li><p>Apple is using Apple Intelligence, a suite of tools for generating images and text, to upsell the iPhone 16. <a href="https://www.nytimes.com/2024/09/09/technology/personaltech/iphone-ai-upgrade.html">But you can get similar features elsewhere</a>.</p></li><li><p>A version of Elon Musk powered by A.I. has appeared in thousands of inauthentic ads, <a href="https://www.nytimes.com/interactive/2024/08/14/technology/elon-musk-ai-deepfake-scam.html">contributing to billions in fraud</a>.</p></li><li><p>Some entrepreneurs say that A.I. has allowed them to <a href="https://www.nytimes.com/2024/08/18/business/economy/ai-business-startups.html">get their companies off the ground more quickly</a>, accelerating the path to hiring and, ideally, profitability.</p></li></ul></section></div></div></article></div></div></div>
  </body>
</html>
