<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>OpenAI Disrupts Iranian Misinformation Campaign | Khanh's feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nytimes.com/2024/08/16/technology/openai-chatgpt-iran-misinformation.html">Original</a>
    <h1>OpenAI Disrupts Iranian Misinformation Campaign</h1>
    
    <div id="readability-page-1" class="page"><div id="site-content"><div><article id="story"><header><p id="article-summary">The company said the Iranian effort, which used ChatGPT, did not gain much traction.</p><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="imageContainer-children-Image"><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcset="https://static01.nyt.com/images/2024/08/16/multimedia/16openai-disinfoy-qkjt/16openai-disinfoy-qkjt-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcset="https://static01.nyt.com/images/2024/08/16/multimedia/16openai-disinfoy-qkjt/16openai-disinfoy-qkjt-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcset="https://static01.nyt.com/images/2024/08/16/multimedia/16openai-disinfoy-qkjt/16openai-disinfoy-qkjt-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"/><img alt="A person at a laptop computer uses ChatGPT." src="https://static01.nyt.com/images/2024/08/16/multimedia/16openai-disinfoy-qkjt/16openai-disinfoy-qkjt-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale" srcset="https://static01.nyt.com/images/2024/08/16/multimedia/16openai-disinfoy-qkjt/16openai-disinfoy-qkjt-articleLarge.jpg?quality=75&amp;auto=webp 600w,https://static01.nyt.com/images/2024/08/16/multimedia/16openai-disinfoy-qkjt/16openai-disinfoy-qkjt-jumbo.jpg?quality=75&amp;auto=webp 1024w,https://static01.nyt.com/images/2024/08/16/multimedia/16openai-disinfoy-qkjt/16openai-disinfoy-qkjt-superJumbo.jpg?quality=75&amp;auto=webp 2048w" sizes="((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 60vw, 100vw" decoding="async" width="600" height="433"/></picture></div><figcaption data-testid="photoviewer-children-ImageCaption"><span>In May, OpenAI said it had disrupted five other online influence campaigns.</span><span><span>Credit...</span><span><span aria-hidden="false">Frank Rumpenhorst/picture alliance, via Getty Images</span></span></span></figcaption></figure></div><div><div><p><a href="https://www.nytimes.com/by/cade-metz"><img alt="Cade Metz" title="Cade Metz" src="https://static01.nyt.com/images/2018/11/26/multimedia/author-cade-metz/author-cade-metz-thumbLarge.png"/></a></p></div></div><div data-testid="reading-time-module"><p><time datetime="2024-08-16T14:20:56-04:00"><span>Aug. 16, 2024</span><span>Updated <span>2:20 p.m. ET</span></span></time></p></div></header><section name="articleBody"><div><div><p>OpenAI said on Friday that it had discovered and disrupted an Iranian influence campaign that used the company’s generative artificial intelligence technologies to spread misinformation online, including content related to the U.S. presidential election.</p><p>The San Francisco A.I. company said it had banned several accounts linked to the campaign from its online services. The Iranian effort, OpenAI added, did not seem to reach a sizable audience.</p><p>“The operation doesn’t appear to have benefited from meaningfully increased audience engagement because of the use of A.I.,” said Ben Nimmo, a principal investigator for OpenAI who has spent years tracking covert influence campaigns from positions at companies including OpenAI and Meta. “We did not see signs that it was getting substantial engagement from real people at all.”</p></div></div><div><p>The popularity of generative A.I. like OpenAI’s online chatbot, ChatGPT, has raised questions about how such technologies might contribute to online disinformation, especially in a year when there are major elections across the globe.</p></div><div><div><p>In May, OpenAI <a href="https://www.nytimes.com/2024/05/30/technology/openai-influence-campaigns-report.html" title="">released</a> a first-of-its-kind report showing that it had identified and disrupted five other online campaigns that used its technologies to deceptively manipulate public opinion and influence geopolitics. Those efforts were run by state actors and private companies in Russia, China and Israel as well as Iran.</p><p>These covert operations used OpenAI’s technology to generate social media posts, translate and edit articles, write headlines and debug computer programs, typically to win support for political campaigns or to swing public opinion in geopolitical conflicts.</p><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><div data-testid="lazy-image"></div></div><figcaption data-testid="photoviewer-children-caption"><span>An example of the campaign uncovered by OpenAI to manipulate public opinion.</span><span><span>Credit...</span><span><span aria-hidden="false">via OpenAI</span></span></span></figcaption></figure></div><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="photoviewer-children-figure"><p><span>Image</span></p><div data-testid="lazy-image"></div></div><figcaption data-testid="photoviewer-children-caption"><span>An example of the Iranian-backed Storm-2035 campaign, which used ChatGPT to generate content around topics including the U.S. presidential election. </span><span><span>Credit...</span><span><span aria-hidden="false">via OpenAI</span></span></span></figcaption></figure></div></div></div><div><div><p>This week, OpenAI identified several ChatGPT accounts that were using its chatbot to generate text and images for a covert Iranian campaign that the company called Storm-2035. The company said the campaign had used ChatGPT to generate content related to a variety of topics, including commentary on candidates in the U.S. presidential election.</p><p>In some cases, the commentary seemed progressive. In other cases, it seemed conservative. It also dealt with hot-button topics ranging from the war in Gaza to Scottish independence.</p><p>The campaign, OpenAI said, used its technologies to generate articles and shorter comments posted on websites and on social media. In some cases, the campaign used ChatGPT to rewrite comments posted by other social media users.</p><p>OpenAI added that a majority of the campaign’s social media posts had received few or no likes, shares or comments, and that it had found little evidence that web articles produced by the campaigns were shared across social media.</p></div></div></section><div><div><div><p>Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and other emerging areas of technology.<span> <a href="https://www.nytimes.com/by/cade-metz">More about Cade Metz</a></span></p></div></div></div><div><section id="styln-guide" role="complementary" aria-labelledby="styln-guide-title"><hr/><h2 id="styln-guide-title">Explore Our Coverage of Artificial Intelligence</h2><hr/><p><strong>News</strong><strong> and Analysis</strong></p><ul><li><p>A California bill that would require companies to test the safety of A.I. technologies before releasing them to the public is <a href="https://www.nytimes.com/2024/08/14/technology/ai-california-bill-silicon-valley.html?region=BELOW_MAIN_CONTENT&amp;block=storyline_flex_guide_recirc&amp;name=styln-artificial-intelligence&amp;variant=show&amp;pgtype=Article">causing alarm in Silicon Valley</a>.</p></li><li><p>In a report, OpenAI revealed that it had considered the potential for users to <a href="https://www.nytimes.com/2024/08/09/style/openai-chatgp?region=BELOW_MAIN_CONTENT&amp;block=storyline_flex_guide_recirc&amp;name=styln-artificial-intelligence&amp;variant=show&amp;pgtype=Article">form an emotional reliance</a> on ChatGPT’s new, humanlike voice mode.</p></li><li><p>Google, Microsoft and Amazon have made deals with A.I. start-ups for their technology and top employees, but have shied from owning the firms. <a href="https://www.nytimes.com/2024/08/08/technology/ai-start-ups-google-microsoft-amazon.html?region=BELOW_MAIN_CONTENT&amp;block=storyline_flex_guide_recirc&amp;name=styln-artificial-intelligence&amp;variant=show&amp;pgtype=Article">Here’s why</a>.</p></li></ul><hr/><p><strong>The Age of A.I.</strong></p><ul><li><p>Hollywood actors and writers won strict limits on A.I. in contract negotiations, <a href="https://www.nytimes.com/2024/07/30/business/economy/artificial-intelligence-hollywood-unions.html?region=BELOW_MAIN_CONTENT&amp;block=storyline_flex_guide_recirc&amp;name=styln-artificial-intelligence&amp;variant=show&amp;pgtype=Article">but movie editors and artists face a growing challenge</a>.</p></li><li><p>As health insurance plans increasingly rely on technology to deny treatment, physicians are <a href="https://www.nytimes.com/2024/07/10/health/doctors-insurers-artificial-intelligence.html?region=BELOW_MAIN_CONTENT&amp;block=storyline_flex_guide_recirc&amp;name=styln-artificial-intelligence&amp;variant=show&amp;pgtype=Article">fighting back with chatbots</a> that synthesize research and make the case.</p></li><li><p>The inventor and futurist Ray Kurzweil hopes to reach “the Singularity” and live indefinitely. <a href="https://www.nytimes.com/2024/07/04/technology/ray-kurzweil-singularity.html?region=BELOW_MAIN_CONTENT&amp;block=storyline_flex_guide_recirc&amp;name=styln-artificial-intelligence&amp;variant=show&amp;pgtype=Article">His margin of error at 76 is shrinking</a>.</p></li></ul></section></div></article></div></div></div>
  </body>
</html>
