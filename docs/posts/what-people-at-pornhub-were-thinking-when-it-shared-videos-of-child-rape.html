<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>What People at Pornhub Were Thinking When It Shared Videos of Child Rape | Khanh's feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nytimes.com/2025/05/10/opinion/pornhub-children-documents.html">Original</a>
    <h1>What People at Pornhub Were Thinking When It Shared Videos of Child Rape</h1>
    
    <div id="readability-page-1" class="page"><article id="story"><header><p>Nicholas Kristof</p><p><time datetime="2025-05-10T07:00:09-04:00">May 10, 2025, <span>7:00 a.m. ET</span></time></p><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="imageContainer-children-Image"><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcset="https://static01.nyt.com/images/2025/05/11/opinion/07kristof-image/07kristof-image-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcset="https://static01.nyt.com/images/2025/05/11/opinion/07kristof-image/07kristof-image-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcset="https://static01.nyt.com/images/2025/05/11/opinion/07kristof-image/07kristof-image-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"/><img alt="An illustration of a girl without a face against a black background." src="https://static01.nyt.com/images/2025/05/11/opinion/07kristof-image/07kristof-image-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale" srcset="https://static01.nyt.com/images/2025/05/11/opinion/07kristof-image/07kristof-image-articleLarge.jpg?quality=75&amp;auto=webp 600w,https://static01.nyt.com/images/2025/05/11/opinion/07kristof-image/07kristof-image-jumbo.jpg?quality=75&amp;auto=webp 1024w,https://static01.nyt.com/images/2025/05/11/opinion/07kristof-image/07kristof-image-superJumbo.jpg?quality=75&amp;auto=webp 2048w" sizes="((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 80vw, 100vw" decoding="async" width="600" height="600"/></picture></div><figcaption data-testid="photoviewer-children-ImageCaption"><span><span>Credit...</span><span><span aria-hidden="false">Najeebah Al-Ghadban</span></span></span></figcaption></figure></div></header><section name="articleBody"><div data-testid="companionColumn-0"><div><p>What goes through the minds of people working at porn companies profiting from videos of children being raped?</p><p>Thanks to a filing error in a Federal District Court in Alabama, releasing thousands of pages of internal documents from Pornhub that were meant to be sealed, we now know. The documents, mostly dating from 2020 or earlier, show some employees laughing off what’s on their site.</p><p>“I hope I never get in trouble for having those vids on my computer LOOOOL,” one messaged another.</p><p>Others are somber, with one messaging another, “There is A LOT of very, very obvious and disturbing CSAM here.” CSAM stands for child sexual abuse material.</p><p>One internal document indicates that Pornhub as of May 2020 had 706,000 videos available on the site that had been flagged by users for depicting rape or assaults on children or for other problems. That was partly because, the documents suggest, Pornhub did not necessarily review a video for possible removal until it had been flagged at least 16 times.</p></div></div><div data-testid="companionColumn-1"><div><p>The company also made it much more difficult to flag problem videos by allowing only registered users to do so. One internal message noted: This “will greatly reduce overall flag volume.”</p><p>Pornhub and other “tube” websites that are <a href="https://www.aylo.com/brands/" title="" rel="noopener noreferrer" target="_blank">part of the same company</a> — like Redtube, Tube8 and YouPorn — don’t make sex videos themselves. Rather, they provide a platform for users to post videos.</p><p>Pornhub executives and owners told me they couldn’t comment on the discovery documents, which I was able to see on a court website, or anything related to current litigation. But they emphasized that the company has tightened its policies since the period covered by the documents, and they argued that it is now working hard to keep nonconsensual material off the site. And in fairness, it does seem that there has been significant improvement.</p><p>Yet these documents lift the curtain on what the company was doing behind the scenes up to that point. And that was: a relentless pursuit of market share without much concern for the well-being of those in the videos.</p><p>To me, the documents underscore how primal the pursuit of profits can be and why we should never trust tech companies to police themselves. And there’s evidence that suggests that, despite changes in the past few years, Pornhub has not gone far enough in eliminating from the platform videos that appear to be of child rapes.</p></div></div><div data-testid="companionColumn-2"><div><p>In the message traffic, one employee advises another not to copy a manager when they find sex videos with children. The other has the obvious response: “He doesn’t want to know how much C.P. we have ignored for the past five years?” C.P. is short for child pornography.</p><p>Indeed, one private memo acknowledged that videos with apparent child sexual abuse had been viewed 684 million times before being removed.</p><p>Internal memos seem to show executives obsessed with making money by attracting the biggest audiences they could, pedophiles included. In one memo, Pornhub managers proposed words to be banned from video descriptions — such as “infant” and “kiddy” — while recommending that the site continue to allow “brutal,” “childhood,” “force,” “snuffs,” “unwilling,” “minor” and “wasted.”</p><p>One internal note says that a person who posted a sexual video of a child shouldn’t be banned from the site because “the user made money.”</p><p>Pornhub produced these documents during discovery in a civil suit by an Alabama woman who beginning at age 16 was filmed engaging in sex acts, including at least once when she was drugged and then raped. These videos of her were posted on Pornhub and amassed thousands of views.</p></div></div><div data-testid="companionColumn-3"><div><p>Some discovery materials also appeared in court filings in a parallel California suit by Serena Fleites, who made a naked video of herself when she was in the eighth grade at the request of a boy she had a crush on. The video ended up on Pornhub, and classmates shamed her. She dropped out of school, self-medicated with drugs and ended up homeless — all while Pornhub profited from the video, which amassed more than 2.7 million views.</p><p>I published an article in December 2020 called “<a href="https://www.nytimes.com/2020/12/04/opinion/sunday/pornhub-rape-trafficking.html" title="">The Children of Pornhub</a>,” quoting Serena and other youths and noting that the website then was infested with rape videos. Girls and boys tearfully told me their sexual abuse had been horrific but brief, while the ongoing sharing of videos on Pornhub made them feel that the assaults were never-ending. Several girls I spoke to, including Serena, had attempted suicide.</p><p>Within days of the article’s publication, Pornhub removed around 10 million videos, some three-quarters of its total, for which it lacked consent. Criminal investigations and legislative hearings began, and victims filed a series of lawsuits. And while I’ve written about terrorists, gangsters and extremists, I got more death threats after that article than from any I’ve ever written.</p><p>With a tone that’s corporate rather than prurient, the materials underscore that Pornhub is in many ways a tech behemoth whose edge is expertise in search engine optimization. It figured out how to label and tag videos so that if someone searched on Google for, say, “gorgeous teen strips naked” or “stop, it hurts porn video” the top result would lead to Pornhub rather than to a rival porn site (those are real examples that lead to Pornhub).</p><p>Pornhub executives clearly had some concern about illegal content, such as sex videos involving people who were 17 or younger, and the internal memos document efforts to remove the most obvious child videos (one staff member said “obvious” problems would be a “3-year-old”). But my impression is that Pornhub managers felt conflicted, because they closely tracked the popularity of topics and saw that videos of naked teenagers were a huge draw. The term “teen” sometimes ranked as high as second in search on Pornhub (“lesbian” then ranked No. 1).</p></div></div><div data-testid="companionColumn-4"><div><p>It’s true, of course, that “teen” can refer to an 18- or 19-year-old adult. But another internal Pornhub message observed that the website didn’t block “very young teen.” And note that children cannot legally consent, nor can parents consent on their behalf; underage sex videos are rape videos.</p><p>The memos emerging in discovery show Pornhub wrestling with what to ban without losing too much popular content. In one set of messages, executives discuss whether to ban the use of the phrases “young girl,” “first anal crying” and “abused by daddy.” In the end, they decide that those terms are acceptable.</p><p>In yet another message, staff members note that the Pornhub algorithm offered as related searches “12 years old” and “little young girl.” An internal message from 2020 notes that a filter for “underage” turned up 183,301 videos on the site.</p><p>One discovery memo showed that there were 155,447 videos on Pornhub with the keyword “12yo.” Other categories that the company tracked were “11yo,” “degraded teen,” “under 10” and “extreme choking.” (It has since removed these searches.)</p><p><strong>I reached out to women</strong> who were victimized by Pornhub to get their reactions to the Pornhub corporate documents.</p></div></div><div data-testid="companionColumn-5"><div><p>Stephanie Stewart was growing up in a conservative Christian household, and she had never kissed a boy when at the age of 15 she was taken by a friend, a girl, to a stranger’s house — and that’s the last she remembers of the evening. Somehow she got home, and she slept for more than a day before getting up with a terrible headache. Her memories are hazy, and in retrospect she is sure that she was drugged.</p><p>Stewart didn’t know what had happened, but after that, everything changed. Kids at school insulted her, calling her a slut. Her mother, a doctor in town, got calls saying, <em>Your daughter is a whore.</em></p><p>“People were mocking me, and it was just a nightmare,” Stewart recalled. So she dropped out of school and earned a G.E.D.</p><p>Finally someone emailed her a Pornhub link, and she clicked on it — and then vomited.</p><p>“I was totally shattered,” she recalled. The video, some 45 minutes long, showed Stewart being raped by four men in their late 20s or older. Stewart doesn’t know who they were, and they were never held accountable. When she saw it, the video had more than one million views.</p><p>Stewart became afraid to leave her house. She recalled sending notes to Pornhub pleading that it take down the video, explaining that she was a minor and was shown being raped. Nothing happened, she said. “I even posted comments on the video saying, ‘I’m underage, take this video off,’ and got no responses from anyone ever,” she told me.</p></div></div><div data-testid="companionColumn-6"><div><p>She had to deal with stalkers who found where she worked and drove past her, shouting vulgarities. Stewart fell into severe depression, requiring years of therapy.</p><p>In hopes of getting help removing the video, Stewart went to the police. “That was absolutely humiliating,” she recalled. “You know, I had to play the video for them on my phone while I’m standing there.” And after all that, the police officers said they couldn’t help.</p><p>Stewart finally filed a report with the <a href="https://www.missingkids.org/home" title="" rel="noopener noreferrer" target="_blank">National Center for Missing &amp; Exploited Children</a>, which got the video removed in 2020. But the trauma remains.</p><p>“I don’t think there’s enough words to say how horrible it’s been dealing with,” she told me. “It’s something I think about every single day.”</p><p>What the discovery documents signify, she said, is that the Pornhub executives had scorn for victims. “They don’t care,” she said. “It’s money in their pockets.”</p></div></div><div data-testid="companionColumn-7"><div><p>It was wrenching for Stewart to talk about what she had endured, and she and her family debated whether she should let me publish her name. In the end, she agreed, so I asked her why.</p><p>“I am sharing my story because I want there to be laws and safeguards in place to prevent this from happening to anyone else,” she said.</p><p><strong>Under great pressure</strong> from criminal investigations and civil suits, Pornhub has become much better in recent years at removing videos on request and at controlling content. After my article, it stopped allowing downloads, as I had called on it to do, and became more serious about blocking videos of children or of rapes. It began verifying age and consent. By July, it says, it will have verified that everyone in all of its library of videos is consenting and an adult.</p><p>The system can be gamed, though (if a face is blurred, who’s to know if the consent form is from that person or someone else?). But the push for consent has meant that there appear to be far fewer videos of rape, torture or assaults on children.</p><p>“This is a massive undertaking,” said Solomon Friedman, a partner in a private equity firm that calls itself Ethical Capital Partners, which purchased Pornhub two years ago. Friedman told me that the site has banned 60,000 words, phrases and word/emoji combinations (like underage, r*pe and hypnosis) and has 20 percent of its employees now working in moderation and other safety areas.</p></div></div><div data-testid="companionColumn-8"><div><p>While some progress seems real, I remain skeptical — partly because the company offered me similar assurances of safety five years ago as it presented itself as “<a href="https://x.com/Pornhub/status/1261008734538600448" title="" rel="noopener noreferrer" target="_blank">wholesome Pornhub</a>.” Many of Pornhub’s managers from that time remain with the company, and the website still seems to me to wink at pedophiles and sadists.</p><p>In searches, I found that it is no longer possible to search for terms like “minor” and “unwilling.” But there are countless references to videos with the words “it hurts” or “painful,” or about “schoolgirls” or “school.”</p><p>Pornhub seems more careful in English and with Americans, perhaps because it’s more likely to get in trouble here with such content. So it doesn’t allow searches for “juveniles,” “youth” or “adolescents.” But searches for the Spanish “joven” (young) produce a cornucopia of videos, and then Pornhub suggests also searching for “jovencita” (young girl or young woman). It has many videos of “adolesentes,” a misspelling of the Spanish word for adolescents, and then suggests searching for a vulgar Spanish term meaning “13-year-old girls having sex.”</p><p>Laila Mickelwait, a dogged pursuer of Pornhub at the <a href="https://justicedefensefund.org/" title="" rel="noopener noreferrer" target="_blank">Justice Defense Fund</a> and author of a book, “<a href="https://takedownbook.com/" title="" rel="noopener noreferrer" target="_blank">Takedown</a>,” about her efforts to hold the company accountable, says that there is still plenty of unverified content on the site that Pornhub is making money from.</p><p>“Illegal content is still proliferating on Pornhub,” Mickelwait told me. “Pornhub doesn’t seem to care.”</p></div></div><div data-testid="companionColumn-9"><div><p>Yet Mickelwait also acknowledges the progress. “Once they realize the risk is greater than the benefit, they’re forced to change,” she said.</p><p><strong>And that in turn points</strong>, imperfectly, to solutions.</p><p>I suspect porn will always be with us. But it seems plausible to me that we can use civil and criminal penalties to incentivize the pornography industry to show only videos for which the website has verified age and consent.</p><p>“The key here is money,” Michael J. Bowe, a lawyer in New York who is representing Serena, told me, referring to the financial system that supports companies hosting underage videos. If the financial infrastructure demands better, he said, companies will follow — and for that reason he has sued Visa and two investment firms that he argues enabled Pornhub in exploiting Serena. (The judge <a href="https://www.courthousenews.com/judge-tentatively-dismisses-visa-from-pornhub-sex-trafficking-lawsuits/" title="" rel="noopener noreferrer" target="_blank">signaled</a> he might drop Visa from the case.)</p><p>For similar reasons, Justine J. Li, a tech professional and entrepreneur, has founded a company called <a href="https://prune.co/" title="" rel="noopener noreferrer" target="_blank">Prune</a> that pressures web hosts, payment systems, ad networks and domain registrars to keep their distance from websites publishing nonconsensual porn.</p><p>“We just need to make it more expensive, more complicated and less profitable to operate without accountability,” she said.</p></div></div><div data-testid="companionColumn-10"><div><p>Li’s interest is personal as well as professional: She was a student at Princeton when a sexual video taken of her when she was underage showed up on Pornhub. At one point, she was hospitalized after a suicide attempt. But she found catharsis in starting Prune, which also offers victims free assistance in removing videos from porn sites.</p><p>Google is a part of the problem, too, for it has been central to the business model of companies publishing nonconsensual imagery. A Google search for “choking porn videos” leads to just that. And Google also directs users to at least one website that monetizes assaults on victims of human trafficking. (Unlike Google, I’m not going to name the site and help it earn profits.)</p><p>Granted, there are gray areas: What about young-looking 18-year-olds who wear pigtails and appeal to pedophiles by appearing much younger? What about videos showing whippings or painful sex, even if the person has agreed to accept money (or drugs) in exchange? A.I. is revolutionizing porn and presents its own issues: What about realistic-looking A.I. depictions of children being raped?</p><p>I’m not sure precisely where the boundaries should be. But to understand why trusting tech companies to make the call is a mistake, consider an Alabama man named Rocky Franklin who was sentenced in 2022 to <a href="https://www.justice.gov/usao-mdal/pr/man-sentenced-40-years-sexual-exploitation-child-advertising-child-porn-and" title="" rel="noopener noreferrer" target="_blank">40 years</a> in prison for sexually exploiting minors. A <a href="https://www.documentcloud.org/documents/25049241-pornhub-alabama-amended-complaint-20240806/" title="" rel="noopener noreferrer" target="_blank">lawsuit</a> filed last year says that Franklin had filmed abuse of a 12-year-old boy and posted the videos on Pornhub — where they reportedly attracted 188,000 views.</p><p>So the abuser was imprisoned, but Pornhub won ad revenue as it shared the abuse with people around the country.</p></div></div><div data-testid="companionColumn-11"><div><p>When people like Harvey Weinstein or Bill Cosby or Jeffrey Epstein are credibly accused of abusing a dozen or more women or girls, we respond with revulsion and a chorus of demands for tough criminal penalties. As we should. But when major international corporations like Pornhub, backed by financiers and search engines, prey on countless thousands of girls, we seem to accept that as just how business works.</p><p>So as I put down this trove of discovery documents from Pornhub, I keep thinking: Why have we let corporations get away with abusing children?</p></div></div></section><div><div><p>A version of this article appears in print on <span> </span>, Section </p><!-- --><p>SR</p><!-- --><p>, Page </p><!-- --><p>10</p><!-- --><p> of the New York edition</p><!-- --><p> with the headline: </p><!-- --><p>Glimpses Behind the Scenes at Pornhub <span>. <a href="https://nytimes.wrightsmedia.com/">Order Reprints</a> | <a href="https://www.nytimes.com/section/todayspaper">Today’s Paper</a> | <a href="https://www.nytimes.com/subscriptions/Multiproduct/lp8HYKU.html?campaignId=48JQY">Subscribe</a></span></p></div></div></article></div>
  </body>
</html>
