<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>That Voice on the Phone May Just Be A.I. | Khanh's feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nytimes.com/2024/10/10/opinion/ai-voice-telemarketers.html">Original</a>
    <h1>That Voice on the Phone May Just Be A.I.</h1>
    
    <div id="readability-page-1" class="page"><article id="story"><header><p>Guest Essay</p><p><time datetime="2024-10-10T05:02:10-04:00">Oct. 10, 2024</time></p><div data-testid="imageblock-wrapper"><figure aria-label="media" role="group"><div data-testid="imageContainer-children-Image"><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcset="https://static01.nyt.com/images/2024/10/13/opinion/13ratliff/10ratliff-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcset="https://static01.nyt.com/images/2024/10/13/opinion/13ratliff/10ratliff-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"/><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcset="https://static01.nyt.com/images/2024/10/13/opinion/13ratliff/10ratliff-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"/><img alt="An illustration of a person looking at a digitized reflection of himself in a body of water." src="https://static01.nyt.com/images/2024/10/13/opinion/13ratliff/10ratliff-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale" srcset="https://static01.nyt.com/images/2024/10/13/opinion/13ratliff/10ratliff-articleLarge.jpg?quality=75&amp;auto=webp 600w,https://static01.nyt.com/images/2024/10/13/opinion/13ratliff/10ratliff-jumbo.jpg?quality=75&amp;auto=webp 1024w,https://static01.nyt.com/images/2024/10/13/opinion/13ratliff/10ratliff-superJumbo.jpg?quality=75&amp;auto=webp 1800w" sizes="((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 80vw, 100vw" decoding="async" width="600" height="600"/></picture></div><figcaption data-testid="photoviewer-children-ImageCaption"><span><span>Credit...</span><span><span aria-hidden="false">Brian Blomerth</span></span></span></figcaption></figure></div><div><div><div><p><span itemprop="name">Evan Ratliff</span></p><p>Mr. Ratliff is a journalist and the creator of the podcast “Shell Game.”</p></div></div></div></header><section name="articleBody"><div data-testid="companionColumn-0"><div><p>Earlier this year I called up my good friend Warren to talk about a soccer game we were about to watch on two different coasts. “You pumped for the game tonight?” I asked. “What? Of course I’m pumped,” he said, as we proceeded with our normal pregame chatter. Then Warren noticed something: “You’re speaking in these bite-size chunks that make it sound like maybe this is an A.I. conversation.”</p><p>He had me there.</p><p>The “I” in our call was not me at all but a voice agent I’d created using a professional-grade artificial intelligence clone of my voice. The voice bot was powered by ChatGPT and attached to my phone number — a process that takes less than an hour and is easy for anyone to replicate. As an experiment, I’ve been sending my voice agent out into the world for most of the last year for a podcast called “Shell Game,” about how strangers, colleagues and friends respond to sudden encounters with the A.I. Evan Ratliff.</p><p>What I’ve learned is that interacting with A.I. voice agents will change how we interact with one another: who we trust, what we expect and what we need in our communications. A.I. voice agents are already infiltrating our world: calling us as telemarketers, taking our orders at fast-food drive-throughs, listening to our problems as A.I. therapists or — and this one really hits home, given my occupation — being <a href="https://www.nytimes.com/2024/09/27/podcasts/metas-race-for-your-face-googles-hit-ai-notebook-and-hatgpt.html" title="">employed</a> as A.I. podcast hosts.</p><p>Voice agents have also been touted as a solution to the loneliness epidemic. But when I called a friend of mine and unleashed the A.I. version of me, he later offered the most succinct description of what the whole experience felt like: “It’s so lonely,” he lamented. That sense of loneliness — the base reality that, fundamentally, you are only talking to yourself — may be the most lasting result of all these A.I. conversations.</p></div></div><div data-testid="companionColumn-1"><div><p>Rapid advances in artificial intelligence have tended to spur three broad reactions. Champions of A.I. spin up utopian visions of hyper-efficiency and machine brilliance. Skeptics claim it’s an overhyped technology that’s already hitting a wall. Alarmists sound warnings about A.I.’s most grandiose dangers, predicting it could sweep away whole industries or escape our control. These competing visions obscure an unavoidable reality: A.I. agents are already triggering an avalanche of synthetic conversation, as they are deployed as tireless, unflagging talkers, capable of endless invented chatter. As they improve, it will become increasingly difficult to distinguish these A.I. voice agents from humans and, even when you <em>can</em> identify them, you will still be forced to talk to them.</p><p>Advocates of A.I. try to sell these agents as helpful digital assistants to schedule our appointments or friends who’ll always be there to listen. But the more simulated human conversation I heard, the more it left me craving the real thing: in-person connections with the people I care about, with all the quirks of a meandering human discussion. If the coming onslaught of humanlike A.I. conversation threatens to fill our world with made-up verbal detritus, an audio version of “<a href="https://nymag.com/intelligencer/article/ai-generated-content-internet-online-slop-spam.html" title="" rel="noopener noreferrer" target="_blank">A.I. slop</a>,” then the upside may be that it forces us to appreciate the subtleties of personal interactions that many of us have come to devalue.</p><p>When I set up my A.I. voice clone, the first task I gave it was to mess around with the people who already debase our communications: telemarketers and scammers. At first, the A.I. agent worked just as I hoped. Human callers who reached my A.I. clone by phone quickly grew frustrated with it, in part because it always sounded interested but was never quite buying.</p><p>Soon, though, my A.I. self began receiving calls from other A.I. voice agents just like it, feeling it out for dubious debt relief or health insurance. Voice agents aren’t just a tool to fend off scammers, they’re also a scammer’s dream: never sleeping, cheap to deploy and human-sounding enough to fool some segment of their targets. I witnessed A.I. voice agents strike up conversations with one another, which raised a Zen-like question: If one A.I. voice agent tries to scam another, is anyone’s time being wasted?</p><p>As I provided my A.I. voice agent with more information about me and my life, it evolved into a more credible impersonator of me. Armed with my biography, it attended work meetings on my behalf (off-camera, of course), conducted interviews in my place and even attempted to negotiate business deals. My clone was better at arranging meetings than closing deals, though it handled an important legal conversation with aplomb.</p></div></div><div data-testid="companionColumn-2"><div><p>Along the way, I discovered its singular talent: a knack for endless untruthful riffing that no human can match. I’m not talking about the so-called hallucinations in which chatbots get basic things wrong. I’m talking about a bottomless capacity for mundane small talk, combined with the imperative to make things up just to keep the conversation going.</p><p>Even when my voice agent did a good job masquerading as me, I found that for the people on the other end of the line, having out-loud conversations with A.I. clones upended their sense of reality. When I sent it to talk to my unwitting friends and family, some quickly detected something amiss and hung up. Others embraced the weirdness, or just yelled at it. One person thought that I’d had a mental breakdown. I called him back myself and put his mind at ease — somewhat — but it was the kind of A.I.-generated misunderstanding we’ll all soon be cleaning up.</p><p>Companies are poised to unleash these A.I. voice agents into our world. We humans need to decide how we will adjust to a world flooded with near-human voices. We could, as I have done, fight impostors with impostors, while we go about our lives ignoring the cacophony. Or we could try and reject this technology, carving out no-clone spaces and refusing to patronize the companies that offer a pseudo-human experience instead of a real one.</p><p>If there’s one thing we don’t need, it’s more loneliness, which seems to be the one thing these A.I. voices reliably supply. Their arrival offers a chance to rethink how we use our own voices and to seek out more of the human interactions that they can never replace.</p></div></div></section></article></div>
  </body>
</html>
